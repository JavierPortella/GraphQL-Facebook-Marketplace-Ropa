{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9825e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from json import loads, JSONDecodeError\n",
    "from logging import (\n",
    "    basicConfig,\n",
    "    CRITICAL,\n",
    "    ERROR,\n",
    "    FileHandler,\n",
    "    getLogger,\n",
    "    INFO,\n",
    "    log,\n",
    "    StreamHandler,\n",
    ")\n",
    "from os import getenv, makedirs, path\n",
    "from re import findall\n",
    "from time import localtime, sleep, strftime, time\n",
    "from traceback import TracebackException\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openpyxl import load_workbook, Workbook\n",
    "from pandas import DataFrame\n",
    "from seleniumwire import webdriver\n",
    "from seleniumwire.utils import decode\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,\n",
    "    StaleElementReferenceException,\n",
    "    ElementNotInteractableException,\n",
    ")\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.remote.remote_connection import LOGGER as seleniumLogger\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from urllib3.connectionpool import log as urllibLogger\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9318c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Errores:\n",
    "    \"\"\"\n",
    "    Representa a los errores ocurridos durante la ejecuci贸n de un scraper\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    errores : dict\n",
    "        Conjunto de datos que contiene toda informaci贸n de los errores ocurridos durante la ejecuci贸n del scraper\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    agregar_error(error, enlace):\n",
    "        Agrega la informaci贸n de un error al diccionario de datos errores\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para el objeto Errores\n",
    "        \"\"\"\n",
    "        self._errores = {\n",
    "            \"Clase\": [],\n",
    "            \"Mensaje\": [],\n",
    "            \"Linea de Error\": [],\n",
    "            \"Codigo Error\": [],\n",
    "            \"Publicacion\": [],\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def errores(self):\n",
    "        \"\"\"Retorna el valor actual del diccionario de datos errores\"\"\"\n",
    "        return self._errores\n",
    "\n",
    "    def agregar_error(self, error, enlace):\n",
    "        \"\"\"\n",
    "        Agrega la informaci贸n de un error al diccionario de datos errores\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        error: Exception\n",
    "            Objeto de tipo excepci贸n ocurrida durante la ejecuci贸n del scraper\n",
    "        enlace: str\n",
    "            Enlace de la publicaci贸n de la p谩gina facebook marketplace\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(ERROR, f\"Error:\\n{error}\")\n",
    "        traceback_error = TracebackException.from_exception(error)\n",
    "        error_stack = traceback_error.stack[0]\n",
    "        self._errores[\"Clase\"].append(traceback_error.exc_type)\n",
    "        self._errores[\"Mensaje\"].append(traceback_error._str)\n",
    "        self._errores[\"Linea de Error\"].append(error_stack.lineno)\n",
    "        self._errores[\"Codigo Error\"].append(error_stack.line)\n",
    "        self._errores[\"Publicacion\"].append(enlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abc9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Representa al conjunto de datos generado por el scraper\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dataset : dict\n",
    "        Conjunto de datos que contiene toda informaci贸n extra铆da de una categor铆a de la p谩gina de facebook marketplace\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    agregar_data():\n",
    "        Agrega la informaci贸n de una publicaci贸n al diccionario de datos dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para el objeto Dataset\n",
    "        \"\"\"\n",
    "        self._dataset = {\n",
    "            \"Fecha Extraccion\": [],\n",
    "            \"titulo_marketplace\": [],\n",
    "            \"tiempo_creacion\": [],\n",
    "            \"tipo_delivery\": [],\n",
    "            \"descripcion\": [],\n",
    "            \"disponible\": [],\n",
    "            \"vendido\": [],\n",
    "            \"fecha_union_vendedor\": [],\n",
    "            \"cantidad\": [],\n",
    "            \"precio\": [],\n",
    "            \"tipo_moneda\": [],\n",
    "            \"amount_with_concurrency\": [],\n",
    "            \"latitud\": [],\n",
    "            \"longitud\": [],\n",
    "            \"locacion\": [],\n",
    "            \"locacion_id\": [],\n",
    "            \"name_vendedor\": [],\n",
    "            \"tipo_vendedor\": [],\n",
    "            \"id_vendedor\": [],\n",
    "            \"enlace\": [],\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"Retorna el valor actual del diccionario de datos dataset\"\"\"\n",
    "        return self._dataset\n",
    "\n",
    "    def agregar_data(self, item, fecha_extraccion, enlace):\n",
    "        \"\"\"\n",
    "        Agrega la informaci贸n de una publicaci贸n al dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        item: dict\n",
    "            Conjunto de datos que contiene toda la informaci贸n de una publicaci贸n\n",
    "        fecha_extraccion: str\n",
    "            Fecha actual en la que se cre贸 una publicaci贸n en formato %d/%m/%Y\n",
    "        enlace: str\n",
    "            Enlace de la publicaci贸n de la p谩gina facebook marketplace\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self._dataset[\"titulo_marketplace\"].append(\n",
    "            item.get(\"marketplace_listing_title\")\n",
    "        )\n",
    "        self._dataset[\"tiempo_creacion\"].append(item.get(\"creation_time\"))\n",
    "        self._dataset[\"disponible\"].append(item.get(\"is_live\"))\n",
    "        self._dataset[\"vendido\"].append(item.get(\"is_sold\"))\n",
    "        self._dataset[\"cantidad\"].append(item.get(\"listing_inventory_type\"))\n",
    "        self._dataset[\"name_vendedor\"].append(\n",
    "            item.get(\"story\").get(\"actors\")[0].get(\"name\")\n",
    "        )\n",
    "        self._dataset[\"tipo_vendedor\"].append(\n",
    "            item.get(\"story\").get(\"actors\")[0][\"__typename\"]\n",
    "        )\n",
    "        self._dataset[\"id_vendedor\"].append(item.get(\"story\").get(\"actors\")[0][\"id\"])\n",
    "        self._dataset[\"locacion_id\"].append(item.get(\"location_vanity_or_id\"))\n",
    "        self._dataset[\"latitud\"].append(item.get(\"location\", {}).get(\"latitude\"))\n",
    "        self._dataset[\"longitud\"].append(item.get(\"location\", {}).get(\"longitude\"))\n",
    "        self._dataset[\"precio\"].append(item.get(\"listing_price\", {}).get(\"amount\"))\n",
    "        self._dataset[\"tipo_moneda\"].append(\n",
    "            item.get(\"listing_price\", {}).get(\"currency\")\n",
    "        )\n",
    "        self._dataset[\"amount_with_concurrency\"].append(\n",
    "            item.get(\"listing_price\", {}).get(\"amount_with_offset_in_currency\")\n",
    "        )\n",
    "        self._dataset[\"tipo_delivery\"].append(item.get(\"delivery_types\", [None])[0])\n",
    "        self._dataset[\"descripcion\"].append(\n",
    "            item.get(\"redacted_description\", {}).get(\"text\")\n",
    "        )\n",
    "        self._dataset[\"fecha_union_vendedor\"].append(\n",
    "            item.get(\"marketplace_listing_seller\", {}).get(\"join_time\")\n",
    "        )\n",
    "        data = item.get(\"location_text\", {})\n",
    "        if data:\n",
    "            data = data.get(\"text\")\n",
    "        self._dataset[\"locacion\"].append(data)\n",
    "        self._dataset[\"Fecha Extraccion\"].append(fecha_extraccion)\n",
    "        self._dataset[\"enlace\"].append(enlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abe3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tiempo:\n",
    "    \"\"\"\n",
    "    Representa el tiempo que se demora el scraper en extraer la informaci贸n\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    start : float\n",
    "        Hora actual en segundos\n",
    "    hora_inicio : str\n",
    "        Hora de inicio de la ejecuci贸n del scraper en formato %H:%M:%S\n",
    "    fecha : str\n",
    "        Fecha de las publicaciones a extraer en formato %d/%m/%Y\n",
    "    hora_fin : str\n",
    "        Hora de t茅rmino de la ejecuci贸n del scraper en formato %H:%M:%S\n",
    "    cantidad : int\n",
    "        Cantidad de publicaciones extra铆das de la p谩gina de facebook marketplace\n",
    "    cantidad_real: int\n",
    "        Cantidad real de publicaciones extra铆das de la p谩gina de facebook marketplace\n",
    "    tiempo : str\n",
    "        Tiempo de ejecuci贸n del scraper en formato %d days, %H:%M:%S\n",
    "    productos_por_min : float\n",
    "        Cantidad de publicaciones que puede extraer el scraper en un minuto\n",
    "    productos_por_min_real : float\n",
    "        Cantidad real de publicaciones que puede extraer el scraper en un minuto\n",
    "    num_error : int\n",
    "        Cantidad de errores ocurridos durante la ejecuci贸n del scraper\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    set_param_final():\n",
    "        Establece los par谩metros finales cuando se termina de ejecutar el scraper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fecha_actual):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para el objeto Tiempo\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fecha_actual: str\n",
    "            Fecha en la que se ejecuta el scraper\n",
    "        \"\"\"\n",
    "        self._start = time()\n",
    "        self._hora_inicio = strftime(\"%H:%M:%S\", localtime(self._start))\n",
    "        log(INFO, f\"Hora de inicio: {self._hora_inicio}\")\n",
    "        self._fecha = fecha_actual.strftime(\"%d/%m/%Y\")\n",
    "        self._hora_fin = None\n",
    "        self._cantidad = None\n",
    "        self._cantidad_real = None\n",
    "        self._tiempo = None\n",
    "        self._productos_por_min = None\n",
    "        self._productos_por_min_real = None\n",
    "        self._num_error = None\n",
    "\n",
    "    @property\n",
    "    def cantidad(self):\n",
    "        \"\"\"Retorna el valor actual o asigna un nuevo valor del atributo cantidad\"\"\"\n",
    "        return self._cantidad\n",
    "\n",
    "    @property\n",
    "    def cantidad_real(self):\n",
    "        \"\"\"Retorna el valor actual o asigna un nuevo valor del atributo cantidad_real\"\"\"\n",
    "        return self._cantidad_real\n",
    "\n",
    "    @property\n",
    "    def fecha(self):\n",
    "        \"\"\"Retorna el valor actual del atributo fecha\"\"\"\n",
    "        return self._fecha\n",
    "\n",
    "    @property\n",
    "    def num_error(self):\n",
    "        \"\"\"Retorna el valor actual o asigna un nuevo valor del atributo num_error\"\"\"\n",
    "        return self._num_error\n",
    "\n",
    "    @cantidad.setter\n",
    "    def cantidad(self, cantidad):\n",
    "        self._cantidad = cantidad\n",
    "\n",
    "    @cantidad_real.setter\n",
    "    def cantidad_real(self, cantidad_real):\n",
    "        self._cantidad_real = cantidad_real\n",
    "\n",
    "    @num_error.setter\n",
    "    def num_error(self, num_error):\n",
    "        self._num_error = num_error\n",
    "\n",
    "    def set_param_final(self):\n",
    "        \"\"\"\n",
    "        Establece parametros finales para medir el tiempo de ejecuci贸n del scraper\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        end = time()\n",
    "        self._hora_fin = strftime(\"%H:%M:%S\", localtime(end))\n",
    "        log(INFO, f\"Productos Extra铆dos: {self._cantidad}\")\n",
    "        log(INFO, f\"Hora Fin: {self._hora_fin}\")\n",
    "        total = end - self._start\n",
    "        self._tiempo = str(timedelta(seconds=total)).split(\".\")[0]\n",
    "        self._productos_por_min = round(self._cantidad / (total / 60), 2)\n",
    "        self._productos_por_min_real = round(self._cantidad_real / (total / 60), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e788fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScraperFb:\n",
    "    \"\"\"\n",
    "    Representa a un bot para hacer web scraping en fb marketplace\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    tiempo : Tiempo\n",
    "        Objeto de la clase Tiempo que maneja informaci贸n del tiempo de ejecuci贸n del scraper\n",
    "    driver: webdriver.Chrome\n",
    "        Objeto de la clase webdriver que maneja un navegador para hacer web scraping\n",
    "    wait : WebDriverWait\n",
    "        Objeto de la clase WebDriverWait que maneja el Tiempo de espera durante la ejecuci贸n del scraper\n",
    "    errores : Errores\n",
    "        Objeto de la clase Errores que maneja informaci贸n de los errores ocurridos durante la ejecuci贸n del scraper\n",
    "    data : Dataset\n",
    "        Objeto de la clase Dataset que maneja informaci贸n de las publicaciones extra铆das por el scraper\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    iniciar_sesion():\n",
    "        Iniciar sesi贸n en facebook usando un usuario y contrase帽a\n",
    "    mapear_datos(url):\n",
    "        Mapea y extrae los datos de las publicaciones de una categor铆a\n",
    "    guardar_datos(dataset, filetype, folder, filename):\n",
    "        Guarda los datos o errores obtenidos durante la ejecuci贸n del scraper\n",
    "    guardar_tiempos(filename, sheet_name):\n",
    "        Guarda la informaci贸n del tiempo de ejecuci贸n del scraper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fecha_actual):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para el objeto ScraperFb\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fecha_actual: str\n",
    "            Fecha en la que se ejecuta el scraper\n",
    "        \"\"\"\n",
    "        log(INFO, \"Inicializando scraper\")\n",
    "        self._tiempo = Tiempo(fecha_actual)\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "        chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "        self._driver = webdriver.Chrome(\n",
    "            chrome_options=chrome_options,\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "        )\n",
    "        self._wait = WebDriverWait(self._driver, 10)\n",
    "        self._errores = Errores()\n",
    "        self._data = Dataset()\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\"Retorna el valor actual del atributo data\"\"\"\n",
    "        return self._data\n",
    "\n",
    "    @property\n",
    "    def errores(self):\n",
    "        \"\"\"Retorna el valor actual del atributo errores\"\"\"\n",
    "        return self._errores\n",
    "\n",
    "    def iniciar_sesion(self):\n",
    "        \"\"\"\n",
    "        Inicia sesi贸n en una p谩gina web usando un usuario y contrase帽a\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(INFO, \"Iniciando sesi贸n\")\n",
    "        self._driver.get(\"https://www.facebook.com/\")\n",
    "        self._driver.maximize_window()\n",
    "        username = self._wait.until(EC.presence_of_element_located((By.ID, \"email\")))\n",
    "        password = self._wait.until(EC.presence_of_element_located((By.ID, \"pass\")))\n",
    "        username.clear()\n",
    "        password.clear()\n",
    "        username.send_keys(getenv(\"FB_USERNAME\"))\n",
    "        password.send_keys(getenv(\"FB_PASSWORD\"))\n",
    "        self._wait.until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[name='login']\"))\n",
    "        ).click()\n",
    "        sleep(10)\n",
    "        log(INFO, \"Inicio de sesi贸n con 茅xito\")\n",
    "\n",
    "    def obtener_publicaciones(self, selector, xpath):\n",
    "        \"\"\"\n",
    "        Retornar una lista de publicaciones visibles con respecto a una categor铆a en facebook marketplace\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selector: str\n",
    "            Selector a ser usado para localizar las publicaciones\n",
    "        xpath: str\n",
    "            Ruta de las publicaciones a ser usado por el selector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "        \"\"\"\n",
    "        return self._driver.find_elements(selector, xpath)\n",
    "\n",
    "    def mapear_datos(self, url):\n",
    "        \"\"\"\n",
    "        Mapea y extrae los datos de las publicaciones de una categor铆a\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        url: str\n",
    "            Link de la p谩gina de una categor铆a en facebook marketplace\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(INFO, \"Accediendo a la URL\")\n",
    "        self._driver.execute_script(\"window.open('about:blank', 'newtab');\")\n",
    "        self._driver.switch_to.window(\"newtab\")\n",
    "        self._driver.get(url)\n",
    "        sleep(8)\n",
    "\n",
    "        log(INFO, \"Mapeando Publicaciones\")\n",
    "        ropa = self.obtener_publicaciones(\n",
    "            By.XPATH, '//*[@class=\"xt7dq6l xl1xv1r x6ikm8r x10wlt62 xh8yej3\"]'\n",
    "        )\n",
    "\n",
    "        log(INFO, \"Creando variables\")\n",
    "        # Enteros que hacen referencia a la fecha en que se postea una publicaci贸n y en la que se extrae la informaci贸n\n",
    "        fecha_publicacion = fecha_extraccion = int(\n",
    "            datetime.strptime(self._tiempo.fecha, \"%d/%m/%Y\").timestamp()\n",
    "        )\n",
    "        # Entero que hace referencia al d铆a siguiente de la fecha en la que se extrae la informaci贸n\n",
    "        fecha_flag = fecha_extraccion + 86400\n",
    "        # Cuenta la cantidad de publicaciones que mapea el scraper\n",
    "        i = 0\n",
    "        # Cuenta la cantidad de errores ocurridos durante la ejecuci贸n del mapeo del scraper\n",
    "        e = 0\n",
    "        # Flag para manejar el intento de veces que se\n",
    "        f = 0\n",
    "        while fecha_publicacion >= fecha_extraccion:\n",
    "            try:\n",
    "                log(INFO, f\"Scrapeando item {i + 1}\")\n",
    "                # Eliminar de la memoria requests innecesarios\n",
    "                del self._driver.requests\n",
    "                # Link de la publicaci贸n de facebook\n",
    "                enlace = findall(\n",
    "                    \"(.*)\\/\\?\",\n",
    "                    ropa[i]\n",
    "                    .find_element(By.XPATH, \".//ancestor::a\")\n",
    "                    .get_attribute(\"href\"),\n",
    "                )[0]\n",
    "                # Dar click a la publicaci贸n de facebook\n",
    "                ropa[i].click()\n",
    "                sleep(5)\n",
    "\n",
    "                for request in self._driver.requests:\n",
    "                    # Validar si la api es de graphql\n",
    "                    if not request.response or \"graphql\" not in request.url:\n",
    "                        continue\n",
    "                    # Obtener la respuesta de la api en bytes\n",
    "                    body = decode(\n",
    "                        request.response.body,\n",
    "                        request.response.headers.get(\"Content-Encoding\", \"identity\"),\n",
    "                    )\n",
    "                    # Decodificar la respuesta a utf-8\n",
    "                    decoded_body = body.decode(\"utf-8\")\n",
    "\n",
    "                    # Validar si la respuesta decodificada es la deseada\n",
    "                    if decoded_body.find('\"extensions\":{\"prefetch_uris_v2\"') == -1:\n",
    "                        continue\n",
    "\n",
    "                    # Convertir al formato json la respuesta decodificada anteriormente\n",
    "                    json_data = loads(decoded_body)\n",
    "                    # Extraer la fecha de publicaci贸n\n",
    "                    fecha_publicacion = json_data[\"data\"][\"viewer\"][\n",
    "                        \"marketplace_product_details_page\"\n",
    "                    ][\"target\"][\"creation_time\"]\n",
    "\n",
    "                    # Validar si la fecha de publicaci贸n corresponda a la deseada\n",
    "                    if fecha_publicacion < fecha_flag:\n",
    "                        # Diccionario que contiene toda la informaci贸n de la publicaci贸n\n",
    "                        dato = json_data[\"data\"][\"viewer\"][\n",
    "                            \"marketplace_product_details_page\"\n",
    "                        ][\"target\"]\n",
    "                        log(INFO, f\"{dato['marketplace_listing_title']}\")\n",
    "                        self._data.agregar_data(dato, self._tiempo.fecha, enlace)\n",
    "                        log(INFO, f\"Item {i + 1} scrapeado con 茅xito\")\n",
    "\n",
    "                    break\n",
    "                # Regresar al inicio donde se encuentran todas las publicaciones de facebook\n",
    "                self._driver.execute_script(\"window.history.go(-1)\")\n",
    "\n",
    "            except (\n",
    "                NoSuchElementException,\n",
    "                ElementNotInteractableException,\n",
    "                StaleElementReferenceException,\n",
    "            ) as error:\n",
    "                enlace = None\n",
    "                self._errores.agregar_error(error, enlace)\n",
    "                e += 1\n",
    "\n",
    "            except (KeyError, JSONDecodeError) as error:\n",
    "                self._errores.agregar_error(error, enlace)\n",
    "                e += 1\n",
    "                self._driver.execute_script(\"window.history.go(-1)\")\n",
    "\n",
    "            except Exception as error:\n",
    "                self._errores.agregar_error(error, enlace)\n",
    "                e += 1\n",
    "                i += 1\n",
    "                log(CRITICAL, \"Se detuvo inesperadamente el programa\")\n",
    "                log(CRITICAL, f\"Causa:\\n{error}\")\n",
    "                break\n",
    "\n",
    "            finally:\n",
    "                i += 1\n",
    "                if i == len(ropa):\n",
    "                    self._driver.execute_script(\n",
    "                        \"window.scrollTo(0, document.body.scrollHeight)\"\n",
    "                    )\n",
    "                    sleep(6)\n",
    "                    ropa = self.obtener_publicaciones(\n",
    "                        By.XPATH,\n",
    "                        '//*[@class=\"xt7dq6l xl1xv1r x6ikm8r x10wlt62 xh8yej3\"]',\n",
    "                    )\n",
    "                sleep(2)\n",
    "                log(\n",
    "                    INFO,\n",
    "                    \"-------------------------------------------------------------------\",\n",
    "                )\n",
    "\n",
    "        del self._driver.requests\n",
    "        self._tiempo.cantidad_real = i - e\n",
    "        self._tiempo.num_error = e\n",
    "        log(INFO, f\"Se hall贸 {e} errores\")\n",
    "        log(INFO, \"Fin de la extraccion\")\n",
    "\n",
    "    def guardar_datos(\n",
    "        self,\n",
    "        dataset,\n",
    "        filetype=\"Data\",\n",
    "        folder=\"Data//datos_obtenidos\",\n",
    "        filename=\"fb_data\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Guarda los datos o errores obtenidos durante la ejecuci贸n del scraper\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: dict\n",
    "            Conjunto de datos extra铆dos por el scraper\n",
    "        filetype: str\n",
    "            Indica si la informaci贸n proviene de los datos o de los errores\n",
    "        folder: str\n",
    "            Ruta del archivo\n",
    "        filename: str\n",
    "            Nombre del archivo\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(INFO, f\"Guardando {filetype}\")\n",
    "        df_fb_mkp_ropa = DataFrame(dataset)\n",
    "\n",
    "        if len(df_fb_mkp_ropa) == 0:\n",
    "            log(\n",
    "                INFO,\n",
    "                f\"El archivo de tipo {filetype} no se va a guardar por no tener informaci贸n\",\n",
    "            )\n",
    "            return\n",
    "\n",
    "        if filetype == \"Data\":\n",
    "            df_fb_mkp_ropa.drop(len(df_fb_mkp_ropa) - 1, axis=0, inplace=True)\n",
    "            cantidad = len(df_fb_mkp_ropa)\n",
    "            self._tiempo.cantidad = cantidad\n",
    "        elif filetype == \"Error\":\n",
    "            cantidad = self._tiempo.num_error\n",
    "        else:\n",
    "            log(\n",
    "                INFO,\n",
    "                f\"El archivo de tipo {filetype} no est谩 admitido. Solo se aceptan los valores Data y Error\",\n",
    "            )\n",
    "            return\n",
    "\n",
    "        datetime_obj = datetime.strptime(self._tiempo.fecha, \"%d/%m/%Y\")\n",
    "        filepath = path.join(folder, datetime_obj.strftime(\"%d-%m-%Y\"))\n",
    "        filename = (\n",
    "            filename\n",
    "            + \"_\"\n",
    "            + datetime_obj.strftime(\"%d%m%Y\")\n",
    "            + \"_\"\n",
    "            + str(cantidad)\n",
    "            + \".xlsx\"\n",
    "        )\n",
    "        if not path.exists(filepath):\n",
    "            makedirs(filepath)\n",
    "        df_fb_mkp_ropa.to_excel(path.join(filepath, filename), index=False)\n",
    "        log(INFO, f\"{filetype} Guardados Correctamente\")\n",
    "\n",
    "    def guardar_tiempos(self, filename, sheet_name):\n",
    "        \"\"\"\n",
    "        Guarda la informaci贸n del tiempo de ejecuci贸n del scraper\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            Nombre del archivo\n",
    "        sheet_name: str\n",
    "            Nombre de la hoja de c谩lculo\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(INFO, \"Guardando tiempos\")\n",
    "        self._tiempo.set_param_final()\n",
    "        header_exist = True\n",
    "        if path.isfile(filename):\n",
    "            tiempos = load_workbook(filename)\n",
    "            if sheet_name not in [ws.title for ws in tiempos.worksheets]:\n",
    "                tiempos.create_sheet(sheet_name)\n",
    "                header_exist = False\n",
    "        else:\n",
    "            tiempos = Workbook()\n",
    "            tiempos.create_sheet(sheet_name)\n",
    "            header_exist = False\n",
    "        worksheet = tiempos[sheet_name]\n",
    "        if not header_exist:\n",
    "            keys = cambiar_posiciones(list(self._tiempo.__dict__.keys())[1:], 0, 1)\n",
    "            worksheet.append(keys)\n",
    "        values = cambiar_posiciones(list(self._tiempo.__dict__.values())[1:], 0, 1)\n",
    "        worksheet.append(values)\n",
    "        tiempos.save(filename)\n",
    "        tiempos.close()\n",
    "        log(INFO, \"Tiempos Guardados Correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767432d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_log(\n",
    "    log_folder, log_filename, log_file_mode, log_file_encoding, fecha_actual\n",
    "):\n",
    "    \"\"\"\n",
    "    Funci贸n que configura los logs para rastrear al programa\n",
    "        Parameter:\n",
    "                log_folder (str): Carpeta donde se va a generar el archivo log\n",
    "                log_filename (str): Nombre del archivo log a ser generado\n",
    "                fecha_actual (datetime): Fecha actual de la creaci贸n del archivo log\n",
    "        Returns:\n",
    "                None\n",
    "    \"\"\"\n",
    "    seleniumLogger.setLevel(ERROR)\n",
    "    urllibLogger.setLevel(ERROR)\n",
    "    logger = getLogger(\"seleniumwire\")\n",
    "    logger.setLevel(ERROR)\n",
    "    log_path = path.join(log_folder, fecha_actual.strftime(\"%d-%m-%Y\"))\n",
    "    log_filename = log_filename + \"_\" + fecha_actual.strftime(\"%d%m%Y\") + \".log\"\n",
    "    if not path.exists(log_path):\n",
    "        makedirs(log_path)\n",
    "    basicConfig(\n",
    "        format=\"%(asctime)s %(message)s\",\n",
    "        level=INFO,\n",
    "        handlers=[\n",
    "            StreamHandler(),\n",
    "            FileHandler(\n",
    "                path.join(log_path, log_filename), log_file_mode, log_file_encoding\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def validar_parametros(parametros):\n",
    "    \"\"\"\n",
    "    Funci贸n que valida si los par谩metros a usar est谩n definidos\n",
    "         Parameter:\n",
    "                 parametros (list): Lista de par谩metros\n",
    "\n",
    "        Returns:\n",
    "               None\n",
    "    \"\"\"\n",
    "    for parametro in parametros:\n",
    "        if not parametro:\n",
    "            log(ERROR, \"Par谩metros incorrectos\")\n",
    "            return False\n",
    "    log(INFO, \"Par谩metros v谩lidos\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def cambiar_posiciones(lista, index1, index2):\n",
    "    \"\"\"\n",
    "    Funci贸n que intercambia las posiciones de 2 elementos de un arreglo\n",
    "         Parameter:\n",
    "                 lista (list): Lista no vac铆a de elementos\n",
    "                 index1 (int): Posici贸n del primer elemento\n",
    "                 index2 (int): Posici贸n del segundo elemento\n",
    "\n",
    "        Returns:\n",
    "               list\n",
    "    \"\"\"\n",
    "    if len(lista) == 0:\n",
    "        return []\n",
    "    aux = lista[index2]\n",
    "    lista[index2] = lista[index1]\n",
    "    lista[index1] = aux\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6838bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Formato para el debugger\n",
    "        fecha_actual = datetime.now().date() - timedelta(days=1)\n",
    "        config_log(\"Log\", \"fb_ropa_log\", \"w\", \"utf-8\", fecha_actual)\n",
    "        log(INFO, \"Configurando Formato B谩sico del Debugger\")\n",
    "\n",
    "        # Cargar variables de entorno\n",
    "        log(INFO, \"Cargando Variables de entorno\")\n",
    "        load_dotenv()\n",
    "\n",
    "        # Url de la categor铆a a scrapear\n",
    "        url_ropa = getenv(\"URL_CATEGORY\")\n",
    "\n",
    "        # Par谩metros para guardar la data extra铆da por el scraper\n",
    "        data_filename = getenv(\"DATA_FILENAME\")\n",
    "        data_folder = getenv(\"DATA_FOLDER\")\n",
    "\n",
    "        # Par谩metros para guardar la medici贸n de la ejecuci贸n del scraper\n",
    "        filename_tiempos = getenv(\"FILENAME_TIEMPOS\")\n",
    "        sheet_tiempos = getenv(\"SHEET_TIEMPOS\")\n",
    "\n",
    "        # Par谩metros para guardar los errores durante la ejecuci贸n por el scraper\n",
    "        error_filename = getenv(\"ERROR_FILENAME\")\n",
    "        error_folder = getenv(\"ERROR_FOLDER\")\n",
    "\n",
    "        # Validar par谩metros\n",
    "        if not validar_parametros(\n",
    "            [\n",
    "                url_ropa,\n",
    "                data_filename,\n",
    "                data_folder,\n",
    "                filename_tiempos,\n",
    "                sheet_tiempos,\n",
    "                error_filename,\n",
    "                error_folder,\n",
    "            ]\n",
    "        ):\n",
    "            return\n",
    "\n",
    "        # Inicializar scrapper\n",
    "        scraper = ScraperFb(fecha_actual)\n",
    "\n",
    "        # Iniciar sesi贸n\n",
    "        scraper.iniciar_sesion()\n",
    "\n",
    "        # Extracci贸n de datos\n",
    "        scraper.mapear_datos(url_ropa)\n",
    "\n",
    "        # Guardando la data extra铆da por el scraper\n",
    "        scraper.guardar_datos(scraper.data.dataset, \"Data\", data_folder, data_filename)\n",
    "\n",
    "        # Guardando los errores extra铆dos por el scraper\n",
    "        scraper.guardar_datos(\n",
    "            scraper.errores.errores, \"Error\", error_folder, error_filename\n",
    "        )\n",
    "\n",
    "        # Guardando los tiempos durante la ejecuci贸n del scraper\n",
    "        scraper.guardar_tiempos(filename_tiempos, sheet_tiempos)\n",
    "        log(INFO, \"Programa finalizado\")\n",
    "    except Exception as error:\n",
    "        log(ERROR, f\"Error: {error}\")\n",
    "        log(INFO, \"Programa ejecutado con fallos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a430409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 02:33:37,813 Configurando Formato B谩sico del Debugger\n",
      "2023-02-02 02:33:37,829 Cargando Variables de entorno\n",
      "2023-02-02 02:33:37,829 Par谩metros v谩lidos\n",
      "2023-02-02 02:33:37,829 Inicializando scraper\n",
      "2023-02-02 02:33:37,829 Hora de inicio: 02:33:37\n",
      "2023-02-02 02:33:37,829 ====== WebDriver manager ======\n",
      "2023-02-02 02:33:38,642 Get LATEST chromedriver version for google-chrome 108.0.5359\n",
      "2023-02-02 02:33:39,892 Driver [C:\\Users\\param\\.wdm\\drivers\\chromedriver\\win32\\108.0.5359\\chromedriver.exe] found in cache\n",
      "2023-02-02 02:33:41,421 Iniciando sesi贸n\n",
      "2023-02-02 02:33:56,730 Inicio de sesi贸n con 茅xito\n",
      "2023-02-02 02:33:56,731 Accediendo a la URL\n",
      "2023-02-02 02:34:19,196 Mapeando Publicaciones\n",
      "2023-02-02 02:34:19,212 Creando variables\n",
      "2023-02-02 02:34:19,212 Scrapeando item 1\n",
      "2023-02-02 02:34:26,791 -------------------------------------------------------------------\n",
      "2023-02-02 02:34:26,792 Scrapeando item 2\n",
      "2023-02-02 02:34:34,051 -------------------------------------------------------------------\n",
      "2023-02-02 02:34:34,051 Scrapeando item 3\n",
      "2023-02-02 02:34:41,274 -------------------------------------------------------------------\n",
      "2023-02-02 02:34:41,275 Scrapeando item 4\n",
      "2023-02-02 02:34:48,586 -------------------------------------------------------------------\n",
      "2023-02-02 02:34:48,586 Scrapeando item 5\n",
      "2023-02-02 02:34:55,806 -------------------------------------------------------------------\n",
      "2023-02-02 02:34:55,806 Scrapeando item 6\n",
      "2023-02-02 02:35:03,015 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:03,015 Scrapeando item 7\n",
      "2023-02-02 02:35:10,240 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:10,240 Scrapeando item 8\n",
      "2023-02-02 02:35:17,463 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:17,463 Scrapeando item 9\n",
      "2023-02-02 02:35:24,624 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:24,624 Scrapeando item 10\n",
      "2023-02-02 02:35:31,811 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:31,811 Scrapeando item 11\n",
      "2023-02-02 02:35:39,002 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:39,002 Scrapeando item 12\n",
      "2023-02-02 02:35:46,181 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:46,181 Scrapeando item 13\n",
      "2023-02-02 02:35:53,437 -------------------------------------------------------------------\n",
      "2023-02-02 02:35:53,437 Scrapeando item 14\n",
      "2023-02-02 02:36:00,646 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:00,646 Scrapeando item 15\n",
      "2023-02-02 02:36:07,837 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:07,837 Scrapeando item 16\n",
      "2023-02-02 02:36:15,026 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:15,027 Scrapeando item 17\n",
      "2023-02-02 02:36:22,207 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:22,207 Scrapeando item 18\n",
      "2023-02-02 02:36:29,424 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:29,425 Scrapeando item 19\n",
      "2023-02-02 02:36:36,633 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:36,633 Scrapeando item 20\n",
      "2023-02-02 02:36:49,873 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:49,873 Scrapeando item 21\n",
      "2023-02-02 02:36:57,086 -------------------------------------------------------------------\n",
      "2023-02-02 02:36:57,086 Scrapeando item 22\n",
      "2023-02-02 02:37:04,265 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:04,265 Scrapeando item 23\n",
      "2023-02-02 02:37:11,453 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:11,453 Scrapeando item 24\n",
      "2023-02-02 02:37:18,643 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:18,643 Scrapeando item 25\n",
      "2023-02-02 02:37:25,842 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:25,842 Scrapeando item 26\n",
      "2023-02-02 02:37:33,058 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:33,058 Scrapeando item 27\n",
      "2023-02-02 02:37:40,255 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:40,255 Scrapeando item 28\n",
      "2023-02-02 02:37:47,457 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:47,457 Scrapeando item 29\n",
      "2023-02-02 02:37:54,632 -------------------------------------------------------------------\n",
      "2023-02-02 02:37:54,632 Scrapeando item 30\n",
      "2023-02-02 02:38:01,880 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:01,881 Scrapeando item 31\n",
      "2023-02-02 02:38:09,151 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:09,151 Scrapeando item 32\n",
      "2023-02-02 02:38:16,362 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:16,362 Scrapeando item 33\n",
      "2023-02-02 02:38:23,584 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:23,584 Scrapeando item 34\n",
      "2023-02-02 02:38:30,763 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:30,764 Scrapeando item 35\n",
      "2023-02-02 02:38:37,956 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:37,956 Scrapeando item 36\n",
      "2023-02-02 02:38:45,146 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:45,146 Scrapeando item 37\n",
      "2023-02-02 02:38:58,393 -------------------------------------------------------------------\n",
      "2023-02-02 02:38:58,393 Scrapeando item 38\n",
      "2023-02-02 02:39:05,616 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:05,616 Scrapeando item 39\n",
      "2023-02-02 02:39:12,818 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:12,821 Scrapeando item 40\n",
      "2023-02-02 02:39:20,023 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:20,024 Scrapeando item 41\n",
      "2023-02-02 02:39:27,245 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:27,245 Scrapeando item 42\n",
      "2023-02-02 02:39:34,414 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:34,414 Scrapeando item 43\n",
      "2023-02-02 02:39:41,607 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:41,607 Scrapeando item 44\n",
      "2023-02-02 02:39:48,818 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:48,818 Scrapeando item 45\n",
      "2023-02-02 02:39:56,075 -------------------------------------------------------------------\n",
      "2023-02-02 02:39:56,075 Scrapeando item 46\n",
      "2023-02-02 02:40:03,246 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:03,246 Scrapeando item 47\n",
      "2023-02-02 02:40:10,441 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:10,441 Scrapeando item 48\n",
      "2023-02-02 02:40:17,657 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:17,657 Scrapeando item 49\n",
      "2023-02-02 02:40:24,864 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:24,864 Scrapeando item 50\n",
      "2023-02-02 02:40:32,092 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:32,093 Scrapeando item 51\n",
      "2023-02-02 02:40:39,315 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:39,315 Scrapeando item 52\n",
      "2023-02-02 02:40:46,518 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:46,518 Scrapeando item 53\n",
      "2023-02-02 02:40:53,816 -------------------------------------------------------------------\n",
      "2023-02-02 02:40:53,816 Scrapeando item 54\n",
      "2023-02-02 02:41:01,036 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:01,036 Scrapeando item 55\n",
      "2023-02-02 02:41:08,211 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:08,211 Scrapeando item 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 02:41:15,410 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:15,411 Scrapeando item 57\n",
      "2023-02-02 02:41:28,684 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:28,684 Scrapeando item 58\n",
      "2023-02-02 02:41:35,895 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:35,895 Scrapeando item 59\n",
      "2023-02-02 02:41:43,079 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:43,079 Scrapeando item 60\n",
      "2023-02-02 02:41:50,260 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:50,260 Scrapeando item 61\n",
      "2023-02-02 02:41:57,530 -------------------------------------------------------------------\n",
      "2023-02-02 02:41:57,530 Scrapeando item 62\n",
      "2023-02-02 02:42:04,930 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:04,946 Scrapeando item 63\n",
      "2023-02-02 02:42:12,195 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:12,213 Scrapeando item 64\n",
      "2023-02-02 02:42:19,419 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:19,421 Scrapeando item 65\n",
      "2023-02-02 02:42:26,594 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:26,594 Scrapeando item 66\n",
      "2023-02-02 02:42:33,768 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:33,768 Scrapeando item 67\n",
      "2023-02-02 02:42:40,971 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:40,972 Scrapeando item 68\n",
      "2023-02-02 02:42:48,154 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:48,155 Scrapeando item 69\n",
      "2023-02-02 02:42:55,370 -------------------------------------------------------------------\n",
      "2023-02-02 02:42:55,371 Scrapeando item 70\n",
      "2023-02-02 02:43:02,587 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:02,588 Scrapeando item 71\n",
      "2023-02-02 02:43:09,774 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:09,774 Scrapeando item 72\n",
      "2023-02-02 02:43:14,938 BOTN DE CUERO TALLA 38\n",
      "2023-02-02 02:43:14,938 Item 72 scrapeado con 茅xito\n",
      "2023-02-02 02:43:16,968 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:16,968 Scrapeando item 73\n",
      "2023-02-02 02:43:22,147 VESTIDOS SUPER FRESCOS HAY TALLAS COMPLETAS SML EN TELA PIEL DE DURAZNO. PRECIO POR MAYOR Y MENOR \n",
      "2023-02-02 02:43:22,163 Item 73 scrapeado con 茅xito\n",
      "2023-02-02 02:43:24,191 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:24,191 Scrapeando item 74\n",
      "2023-02-02 02:43:29,379 Vestido vino talla S / 70 SOLES\n",
      "2023-02-02 02:43:29,379 Item 74 scrapeado con 茅xito\n",
      "2023-02-02 02:43:31,416 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:31,416 Scrapeando item 75\n",
      "2023-02-02 02:43:36,575 Conjuntos de Alianza Lima \n",
      "2023-02-02 02:43:36,575 Item 75 scrapeado con 茅xito\n",
      "2023-02-02 02:43:38,601 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:38,602 Scrapeando item 76\n",
      "2023-02-02 02:43:43,757 Error:\n",
      "'creation_time'\n",
      "2023-02-02 02:43:51,865 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:51,865 Scrapeando item 77\n",
      "2023-02-02 02:43:57,032 39 so. [CASACA JEAN DE GATITOS] \n",
      "2023-02-02 02:43:57,032 Item 77 scrapeado con 茅xito\n",
      "2023-02-02 02:43:59,075 -------------------------------------------------------------------\n",
      "2023-02-02 02:43:59,076 Scrapeando item 78\n",
      "2023-02-02 02:44:04,225 Vestido con abertura糕\n",
      "2023-02-02 02:44:04,225 Item 78 scrapeado con 茅xito\n",
      "2023-02-02 02:44:06,258 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:06,258 Scrapeando item 79\n",
      "2023-02-02 02:44:11,423 Pantal贸n Zara\n",
      "2023-02-02 02:44:11,423 Item 79 scrapeado con 茅xito\n",
      "2023-02-02 02:44:13,459 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:13,460 Scrapeando item 80\n",
      "2023-02-02 02:44:18,630 Slouchy colores nuevos \n",
      "2023-02-02 02:44:18,630 Item 80 scrapeado con 茅xito\n",
      "2023-02-02 02:44:20,670 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:20,671 Scrapeando item 81\n",
      "2023-02-02 02:44:25,825 TOBILLERA DEPORTIVA DE COMPRESIN CON GEL\n",
      "2023-02-02 02:44:25,825 Item 81 scrapeado con 茅xito\n",
      "2023-02-02 02:44:27,862 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:27,862 Scrapeando item 82\n",
      "2023-02-02 02:44:33,054 SE VENDE LEGGINS PUSH UP\n",
      "2023-02-02 02:44:33,054 Item 82 scrapeado con 茅xito\n",
      "2023-02-02 02:44:35,098 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:35,098 Scrapeando item 83\n",
      "2023-02-02 02:44:40,267 Romper Para Ni帽as\n",
      "2023-02-02 02:44:40,267 Item 83 scrapeado con 茅xito\n",
      "2023-02-02 02:44:42,305 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:42,305 Scrapeando item 84\n",
      "2023-02-02 02:44:47,460 Nike Air Force 1\n",
      "2023-02-02 02:44:47,460 Item 84 scrapeado con 茅xito\n",
      "2023-02-02 02:44:49,496 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:49,496 Scrapeando item 85\n",
      "2023-02-02 02:44:54,699 Moda\n",
      "2023-02-02 02:44:54,699 Item 85 scrapeado con 茅xito\n",
      "2023-02-02 02:44:56,730 -------------------------------------------------------------------\n",
      "2023-02-02 02:44:56,730 Scrapeando item 86\n",
      "2023-02-02 02:45:01,899 Remato Zapatillas T39\n",
      "2023-02-02 02:45:01,899 Item 86 scrapeado con 茅xito\n",
      "2023-02-02 02:45:03,931 -------------------------------------------------------------------\n",
      "2023-02-02 02:45:03,931 Scrapeando item 87\n",
      "2023-02-02 02:45:09,090 Vestido princesa Sofia\n",
      "2023-02-02 02:45:09,090 Item 87 scrapeado con 茅xito\n",
      "2023-02-02 02:45:11,122 -------------------------------------------------------------------\n",
      "2023-02-02 02:45:11,123 Scrapeando item 88\n",
      "2023-02-02 02:45:16,282 FULL ALPARGATAS TODO \n",
      "EN STOCK\n",
      "2023-02-02 02:45:16,282 Item 88 scrapeado con 茅xito\n",
      "2023-02-02 02:45:18,321 -------------------------------------------------------------------\n",
      "2023-02-02 02:45:18,321 Scrapeando item 89\n",
      "2023-02-02 02:45:23,474 Conjunto Para Dama\n",
      "2023-02-02 02:45:23,474 Item 89 scrapeado con 茅xito\n",
      "2023-02-02 02:45:25,503 -------------------------------------------------------------------\n",
      "2023-02-02 02:45:25,503 Scrapeando item 90\n",
      "2023-02-02 02:45:30,651 CALZADOS DE STOCK\n",
      "2023-02-02 02:45:30,651 Item 90 scrapeado con 茅xito\n",
      "2023-02-02 02:45:32,695 -------------------------------------------------------------------\n",
      "2023-02-02 02:45:32,695 Scrapeando item 91\n",
      "2023-02-02 02:45:37,848 Vestiso Luisa\n",
      "2023-02-02 02:45:37,848 Item 91 scrapeado con 茅xito\n",
      "2023-02-02 02:45:39,890 -------------------------------------------------------------------\n",
      "2023-02-02 02:45:39,890 Scrapeando item 92\n",
      "2023-02-02 02:45:45,036 SANDALIAS DE NIA DE SEGUNDO USO\n",
      "2023-02-02 02:45:45,036 Item 92 scrapeado con 茅xito\n",
      "2023-02-02 02:45:47,069 -------------------------------------------------------------------\n",
      "2023-02-02 02:45:47,069 Scrapeando item 93\n",
      "2023-02-02 02:45:52,234 Vestido Rib\n",
      "2023-02-02 02:45:52,234 Item 93 scrapeado con 茅xito\n",
      "2023-02-02 02:46:00,346 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:00,346 Scrapeando item 94\n",
      "2023-02-02 02:46:05,496 Moda\n",
      "2023-02-02 02:46:05,496 Item 94 scrapeado con 茅xito\n",
      "2023-02-02 02:46:07,536 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:07,537 Scrapeando item 95\n",
      "2023-02-02 02:46:12,674 Ternos, Sacos Y Blazer\n",
      "2023-02-02 02:46:12,674 Item 95 scrapeado con 茅xito\n",
      "2023-02-02 02:46:14,705 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:14,705 Scrapeando item 96\n",
      "2023-02-02 02:46:19,856 Aquashoes Ni帽a\n",
      "2023-02-02 02:46:19,856 Item 96 scrapeado con 茅xito\n",
      "2023-02-02 02:46:21,896 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:21,896 Scrapeando item 97\n",
      "2023-02-02 02:46:27,038 BLUSA PRINT H&M / XS\n",
      "2023-02-02 02:46:27,038 Item 97 scrapeado con 茅xito\n",
      "2023-02-02 02:46:29,070 -------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 02:46:29,071 Scrapeando item 98\n",
      "2023-02-02 02:46:34,217 SHORT TORERO BORDADO\n",
      "2023-02-02 02:46:34,217 Item 98 scrapeado con 茅xito\n",
      "2023-02-02 02:46:36,256 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:36,258 Scrapeando item 99\n",
      "2023-02-02 02:46:41,431 Vestido Small SPRINGFIELD\n",
      "2023-02-02 02:46:41,431 Item 99 scrapeado con 茅xito\n",
      "2023-02-02 02:46:43,469 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:43,469 Scrapeando item 100\n",
      "2023-02-02 02:46:48,632 Remat贸 vestido de novia\n",
      "2023-02-02 02:46:48,632 Item 100 scrapeado con 茅xito\n",
      "2023-02-02 02:46:50,675 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:50,675 Scrapeando item 101\n",
      "2023-02-02 02:46:55,837 Sandalias Para Beb茅\n",
      "2023-02-02 02:46:55,837 Item 101 scrapeado con 茅xito\n",
      "2023-02-02 02:46:57,879 -------------------------------------------------------------------\n",
      "2023-02-02 02:46:57,879 Scrapeando item 102\n",
      "2023-02-02 02:47:03,058 Hermoso polo \n",
      "2023-02-02 02:47:03,059 Item 102 scrapeado con 茅xito\n",
      "2023-02-02 02:47:05,088 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:05,089 Scrapeando item 103\n",
      "2023-02-02 02:47:10,233 Elegante y bello vestido corto \n",
      "Material satinado \n",
      "Tallas xs hasta la 3 xl 锔\n",
      "2023-02-02 02:47:10,233 Item 103 scrapeado con 茅xito\n",
      "2023-02-02 02:47:12,265 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:12,267 Scrapeando item 104\n",
      "2023-02-02 02:47:17,408 Zapato azul talla 38 Y zandalias  negro talla 37\n",
      "2023-02-02 02:47:17,408 Item 104 scrapeado con 茅xito\n",
      "2023-02-02 02:47:19,444 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:19,444 Scrapeando item 105\n",
      "2023-02-02 02:47:24,630 Carteritas morral de silicona\n",
      "2023-02-02 02:47:24,630 Item 105 scrapeado con 茅xito\n",
      "2023-02-02 02:47:26,666 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:26,666 Scrapeando item 106\n",
      "2023-02-02 02:47:31,846 Polos BOSS caballero\n",
      "2023-02-02 02:47:31,846 Item 106 scrapeado con 茅xito\n",
      "2023-02-02 02:47:33,875 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:33,876 Scrapeando item 107\n",
      "2023-02-02 02:47:39,025 plataforma\n",
      "2023-02-02 02:47:39,025 Item 107 scrapeado con 茅xito\n",
      "2023-02-02 02:47:41,065 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:41,066 Scrapeando item 108\n",
      "2023-02-02 02:47:46,238 PANTALN JEANS STRESH\n",
      "2023-02-02 02:47:46,253 Item 108 scrapeado con 茅xito\n",
      "2023-02-02 02:47:48,299 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:48,299 Scrapeando item 109\n",
      "2023-02-02 02:47:53,491 Cargo Pants\n",
      "2023-02-02 02:47:53,491 Item 109 scrapeado con 茅xito\n",
      "2023-02-02 02:47:55,531 -------------------------------------------------------------------\n",
      "2023-02-02 02:47:55,532 Scrapeando item 110\n",
      "2023-02-02 02:48:00,682 Crocs de ni帽a talla 21/22\n",
      "2023-02-02 02:48:00,682 Item 110 scrapeado con 茅xito\n",
      "2023-02-02 02:48:02,717 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:02,718 Scrapeando item 111\n",
      "2023-02-02 02:48:07,872 Remato SEMINUEVOS \n",
      "c/u 40 soles no menos vestidos americanos\n",
      "2023-02-02 02:48:07,872 Item 111 scrapeado con 茅xito\n",
      "2023-02-02 02:48:09,915 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:09,916 Scrapeando item 112\n",
      "2023-02-02 02:48:15,063 Moda\n",
      "2023-02-02 02:48:15,063 Item 112 scrapeado con 茅xito\n",
      "2023-02-02 02:48:17,104 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:17,104 Scrapeando item 113\n",
      "2023-02-02 02:48:22,278 Wide leg jeans rigido\n",
      "2023-02-02 02:48:22,278 Item 113 scrapeado con 茅xito\n",
      "2023-02-02 02:48:24,313 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:24,314 Scrapeando item 114\n",
      "2023-02-02 02:48:29,484 Pantalon rayado talla L (como nuevo)\n",
      "2023-02-02 02:48:29,484 Item 114 scrapeado con 茅xito\n",
      "2023-02-02 02:48:31,521 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:31,521 Scrapeando item 115\n",
      "2023-02-02 02:48:36,659 Chompa Sudadera Sweatshirt NA Casual Mujer Talla 3XL Style Co\n",
      "2023-02-02 02:48:36,659 Item 115 scrapeado con 茅xito\n",
      "2023-02-02 02:48:44,760 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:44,760 Scrapeando item 116\n",
      "2023-02-02 02:48:49,936 Enterizo Acolchado para beb茅s\n",
      "100% algod贸n |\n",
      "Baby Club Chic\n",
      "2023-02-02 02:48:49,936 Item 116 scrapeado con 茅xito\n",
      "2023-02-02 02:48:51,979 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:51,981 Scrapeando item 117\n",
      "2023-02-02 02:48:57,119 Quicksilver T-shirts\n",
      "2023-02-02 02:48:57,119 Item 117 scrapeado con 茅xito\n",
      "2023-02-02 02:48:59,163 -------------------------------------------------------------------\n",
      "2023-02-02 02:48:59,164 Scrapeando item 118\n",
      "2023-02-02 02:49:04,329 Jacket CARHARTT\n",
      "2023-02-02 02:49:04,329 Item 118 scrapeado con 茅xito\n",
      "2023-02-02 02:49:06,370 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:06,372 Scrapeando item 119\n",
      "2023-02-02 02:49:11,511 Corset..  Almendra (colores variados)\n",
      "2023-02-02 02:49:11,511 Item 119 scrapeado con 茅xito\n",
      "2023-02-02 02:49:13,546 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:13,546 Scrapeando item 120\n",
      "2023-02-02 02:49:18,691 TOP MULTIUSOS\n",
      "2023-02-02 02:49:18,691 Item 120 scrapeado con 茅xito\n",
      "2023-02-02 02:49:20,735 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:20,735 Scrapeando item 121\n",
      "2023-02-02 02:49:25,881 Zapatos Colegio\n",
      "2023-02-02 02:49:25,881 Item 121 scrapeado con 茅xito\n",
      "2023-02-02 02:49:27,916 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:27,917 Scrapeando item 122\n",
      "2023-02-02 02:49:33,068 Zapatillas Ni帽a JoJo Talla 27\n",
      "2023-02-02 02:49:33,068 Item 122 scrapeado con 茅xito\n",
      "2023-02-02 02:49:35,101 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:35,101 Scrapeando item 123\n",
      "2023-02-02 02:49:40,252 Pijama de unicornio rosado\n",
      "2023-02-02 02:49:40,252 Item 123 scrapeado con 茅xito\n",
      "2023-02-02 02:49:42,292 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:42,292 Scrapeando item 124\n",
      "2023-02-02 02:49:47,447 Closet Sale  + Entrega GRATIS\n",
      "2023-02-02 02:49:47,447 Item 124 scrapeado con 茅xito\n",
      "2023-02-02 02:49:49,483 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:49,484 Scrapeando item 125\n",
      "2023-02-02 02:49:54,625 Camiseta Locos Addams Homero y Morticia Polos san Valent铆n\n",
      "2023-02-02 02:49:54,625 Item 125 scrapeado con 茅xito\n",
      "2023-02-02 02:49:56,657 -------------------------------------------------------------------\n",
      "2023-02-02 02:49:56,657 Scrapeando item 126\n",
      "2023-02-02 02:50:01,809 Sandalias Para Ni帽o\n",
      "2023-02-02 02:50:01,809 Item 126 scrapeado con 茅xito\n",
      "2023-02-02 02:50:03,843 -------------------------------------------------------------------\n",
      "2023-02-02 02:50:03,844 Scrapeando item 127\n",
      "2023-02-02 02:50:08,987 Zapatillas Para Damas.\n",
      "2023-02-02 02:50:08,987 Item 127 scrapeado con 茅xito\n",
      "2023-02-02 02:50:11,023 -------------------------------------------------------------------\n",
      "2023-02-02 02:50:11,024 Scrapeando item 128\n",
      "2023-02-02 02:50:16,208 Alpargatas taco cu帽a N* 9\n",
      "2023-02-02 02:50:16,208 Item 128 scrapeado con 茅xito\n",
      "2023-02-02 02:50:18,249 -------------------------------------------------------------------\n",
      "2023-02-02 02:50:18,249 Scrapeando item 129\n",
      "2023-02-02 02:50:23,439 Pantalon De La Marca Speakers Moda En Venta Talla S\n",
      "2023-02-02 02:50:23,439 Item 129 scrapeado con 茅xito\n",
      "2023-02-02 02:50:25,475 -------------------------------------------------------------------\n",
      "2023-02-02 02:50:25,477 Scrapeando item 130\n",
      "2023-02-02 02:50:30,636 Noke Jordan Legacy\n",
      "2023-02-02 02:50:30,636 Item 130 scrapeado con 茅xito\n",
      "2023-02-02 02:50:32,671 -------------------------------------------------------------------\n",
      "2023-02-02 02:50:32,671 Scrapeando item 131\n",
      "2023-02-02 02:50:37,835 Vestido material chalis \n",
      "Super fresca \n",
      "2023-02-02 02:50:37,835 Item 131 scrapeado con 茅xito\n",
      "2023-02-02 02:50:39,873 -------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 02:50:39,873 Scrapeando item 132\n",
      "2023-02-02 02:50:45,019 LINDOS BOTINES DE MODA PARA NIAS COLECCION OTOO-INVIERNO 2022\n",
      "2023-02-02 02:50:45,019 Item 132 scrapeado con 茅xito\n",
      "2023-02-02 02:50:47,064 -------------------------------------------------------------------\n",
      "2023-02-02 02:50:47,064 Scrapeando item 133\n",
      "2023-02-02 02:50:52,212 Carteras Pop It. Magdalena L铆quidaci贸n\n",
      "2023-02-02 02:50:52,212 Item 133 scrapeado con 茅xito\n",
      "2023-02-02 02:50:54,256 -------------------------------------------------------------------\n",
      "2023-02-02 02:50:54,256 Scrapeando item 134\n",
      "2023-02-02 02:50:59,415 OFERTA de Polos para hombres de MARCA de EXPORTACION a precio de FABRICA\n",
      "2023-02-02 02:50:59,415 Item 134 scrapeado con 茅xito\n",
      "2023-02-02 02:51:01,447 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:01,447 Scrapeando item 135\n",
      "2023-02-02 02:51:06,592 Sandalias de tiras talla 35 al 39\n",
      "2023-02-02 02:51:06,592 Item 135 scrapeado con 茅xito\n",
      "2023-02-02 02:51:08,629 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:08,631 Scrapeando item 136\n",
      "2023-02-02 02:51:13,781 Enterizo Vestido Short\n",
      "2023-02-02 02:51:13,781 Item 136 scrapeado con 茅xito\n",
      "2023-02-02 02:51:21,883 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:21,883 Scrapeando item 137\n",
      "2023-02-02 02:51:27,038 Polos, Shorts, Vestidos Y Chavitos, Phuyu New\n",
      "2023-02-02 02:51:27,038 Item 137 scrapeado con 茅xito\n",
      "2023-02-02 02:51:29,074 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:29,074 Scrapeando item 138\n",
      "2023-02-02 02:51:34,221 Ropa ni帽os,mujer y hombre\n",
      "2023-02-02 02:51:34,221 Item 138 scrapeado con 茅xito\n",
      "2023-02-02 02:51:36,264 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:36,264 Scrapeando item 139\n",
      "2023-02-02 02:51:41,411 Zapato de hombre \n",
      "2023-02-02 02:51:41,411 Item 139 scrapeado con 茅xito\n",
      "2023-02-02 02:51:43,438 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:43,439 Scrapeando item 140\n",
      "2023-02-02 02:51:48,573 Ropita de recien nacido en pima\n",
      "2023-02-02 02:51:48,573 Item 140 scrapeado con 茅xito\n",
      "2023-02-02 02:51:50,614 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:50,614 Scrapeando item 141\n",
      "2023-02-02 02:51:55,776 PANTALN JEANS STRETCH A LA CINTURA DE COLORES \n",
      "2023-02-02 02:51:55,776 Item 141 scrapeado con 茅xito\n",
      "2023-02-02 02:51:57,809 -------------------------------------------------------------------\n",
      "2023-02-02 02:51:57,811 Scrapeando item 142\n",
      "2023-02-02 02:52:02,983 Hermoso Vestido\n",
      "2023-02-02 02:52:02,983 Item 142 scrapeado con 茅xito\n",
      "2023-02-02 02:52:05,013 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:05,013 Scrapeando item 143\n",
      "2023-02-02 02:52:10,152 ALE_K BOLSOS\n",
      "2023-02-02 02:52:10,152 Item 143 scrapeado con 茅xito\n",
      "2023-02-02 02:52:12,194 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:12,195 Scrapeando item 144\n",
      "2023-02-02 02:52:17,374 Vestido de Fiesta para Dama\n",
      "2023-02-02 02:52:17,374 Item 144 scrapeado con 茅xito\n",
      "2023-02-02 02:52:19,410 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:19,410 Scrapeando item 145\n",
      "2023-02-02 02:52:24,560 Remato loncheras de mis ni帽os q ya no usan en buen estado .\n",
      "Precio econ贸mico\n",
      "2023-02-02 02:52:24,560 Item 145 scrapeado con 茅xito\n",
      "2023-02-02 02:52:26,601 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:26,601 Scrapeando item 146\n",
      "2023-02-02 02:52:31,750 Luce hermosa - Polo Belleza Peruana\n",
      "2023-02-02 02:52:31,750 Item 146 scrapeado con 茅xito\n",
      "2023-02-02 02:52:33,792 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:33,792 Scrapeando item 147\n",
      "2023-02-02 02:52:38,956 Remato Todo\n",
      "2023-02-02 02:52:38,956 Item 147 scrapeado con 茅xito\n",
      "2023-02-02 02:52:41,000 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:41,000 Scrapeando item 148\n",
      "2023-02-02 02:52:46,167 Sandalias Latina吼糕锔┐\n",
      "2023-02-02 02:52:46,167 Item 148 scrapeado con 茅xito\n",
      "2023-02-02 02:52:48,199 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:48,201 Scrapeando item 149\n",
      "2023-02-02 02:52:53,367 Polos Manga Corta,Manga Cero Para Este Verano Tenemos Variedades De Colores Y Tallas\n",
      "2023-02-02 02:52:53,367 Item 149 scrapeado con 茅xito\n",
      "2023-02-02 02:52:55,416 -------------------------------------------------------------------\n",
      "2023-02-02 02:52:55,416 Scrapeando item 150\n",
      "2023-02-02 02:53:00,581 Zapatillas importadas para ni帽os yomax \n",
      "2023-02-02 02:53:00,581 Item 150 scrapeado con 茅xito\n",
      "2023-02-02 02:53:02,618 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:02,620 Scrapeando item 151\n",
      "2023-02-02 02:53:07,793 Camisas CH Manga Corta Algod贸n Satinado\n",
      "2023-02-02 02:53:07,793 Item 151 scrapeado con 茅xito\n",
      "2023-02-02 02:53:09,833 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:09,834 Scrapeando item 152\n",
      "2023-02-02 02:53:15,022 Lote De Ropa De Segunda De Ni帽oni帽a\n",
      "2023-02-02 02:53:15,022 Item 152 scrapeado con 茅xito\n",
      "2023-02-02 02:53:17,059 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:17,059 Scrapeando item 153\n",
      "2023-02-02 02:53:22,206 PANTALN JEANS STRETCH DE COLORES A LA CINTURA \n",
      "2023-02-02 02:53:22,206 Item 153 scrapeado con 茅xito\n",
      "2023-02-02 02:53:24,240 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:24,241 Scrapeando item 154\n",
      "2023-02-02 02:53:29,413 Pantalon De Colegio\n",
      "2023-02-02 02:53:29,413 Item 154 scrapeado con 茅xito\n",
      "2023-02-02 02:53:31,442 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:31,442 Scrapeando item 155\n",
      "2023-02-02 02:53:36,745 Dress Eleonor\n",
      "2023-02-02 02:53:36,745 Item 155 scrapeado con 茅xito\n",
      "2023-02-02 02:53:38,785 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:38,787 Scrapeando item 156\n",
      "2023-02-02 02:53:43,944 Shores En Tendencia\n",
      "2023-02-02 02:53:43,944 Item 156 scrapeado con 茅xito\n",
      "2023-02-02 02:53:45,989 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:45,991 Scrapeando item 157\n",
      "2023-02-02 02:53:51,133 Zapatillas En Moda\n",
      "2023-02-02 02:53:51,133 Item 157 scrapeado con 茅xito\n",
      "2023-02-02 02:53:53,164 -------------------------------------------------------------------\n",
      "2023-02-02 02:53:53,164 Scrapeando item 158\n",
      "2023-02-02 02:53:58,312 Vestidos \n",
      "2023-02-02 02:53:58,312 Item 158 scrapeado con 茅xito\n",
      "2023-02-02 02:54:00,355 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:00,355 Scrapeando item 159\n",
      "2023-02-02 02:54:05,499 Angela'shop\n",
      "2023-02-02 02:54:05,499 Item 159 scrapeado con 茅xito\n",
      "2023-02-02 02:54:13,606 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:13,606 Scrapeando item 160\n",
      "2023-02-02 02:54:18,764 Falda short jean rigido\n",
      "2023-02-02 02:54:18,764 Item 160 scrapeado con 茅xito\n",
      "2023-02-02 02:54:20,797 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:20,798 Scrapeando item 161\n",
      "2023-02-02 02:54:25,940 Pantalones De Dama Y Ni帽as Tela R铆gida\n",
      "2023-02-02 02:54:25,940 Item 161 scrapeado con 茅xito\n",
      "2023-02-02 02:54:27,983 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:27,983 Scrapeando item 162\n",
      "2023-02-02 02:54:33,138 Sandalia Para Hambre 100% Cuero Nacional\n",
      "2023-02-02 02:54:33,138 Item 162 scrapeado con 茅xito\n",
      "2023-02-02 02:54:35,173 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:35,173 Scrapeando item 163\n",
      "2023-02-02 02:54:40,323 Polos Para SAN VALENTIN\n",
      "2023-02-02 02:54:40,323 Item 163 scrapeado con 茅xito\n",
      "2023-02-02 02:54:42,364 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:42,364 Scrapeando item 164\n",
      "2023-02-02 02:54:47,515 ヰ○  Zapatos de Mujer ○○ ヰ\n",
      "2023-02-02 02:54:47,515 Item 164 scrapeado con 茅xito\n",
      "2023-02-02 02:54:49,555 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:49,555 Scrapeando item 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 02:54:54,708 猴 Zapatos De Mujer \n",
      "2023-02-02 02:54:54,708 Item 165 scrapeado con 茅xito\n",
      "2023-02-02 02:54:56,744 -------------------------------------------------------------------\n",
      "2023-02-02 02:54:56,745 Scrapeando item 166\n",
      "2023-02-02 02:55:01,902 Sandalias modernas 35-39\n",
      "2023-02-02 02:55:01,902 Item 166 scrapeado con 茅xito\n",
      "2023-02-02 02:55:03,937 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:03,939 Scrapeando item 167\n",
      "2023-02-02 02:55:09,088 Zapatos De Cuero Para Ni帽a - TALLA 28\n",
      "2023-02-02 02:55:09,088 Item 167 scrapeado con 茅xito\n",
      "2023-02-02 02:55:11,129 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:11,130 Scrapeando item 168\n",
      "2023-02-02 02:55:16,264 conjunto elegante\n",
      "2023-02-02 02:55:16,264 Item 168 scrapeado con 茅xito\n",
      "2023-02-02 02:55:18,305 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:18,306 Scrapeando item 169\n",
      "2023-02-02 02:55:23,450 Aquashoes\n",
      "2023-02-02 02:55:23,450 Item 169 scrapeado con 茅xito\n",
      "2023-02-02 02:55:25,495 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:25,495 Scrapeando item 170\n",
      "2023-02-02 02:55:30,646 Hermosos overoles de dama\n",
      "2023-02-02 02:55:30,646 Item 170 scrapeado con 茅xito\n",
      "2023-02-02 02:55:32,680 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:32,681 Scrapeando item 171\n",
      "2023-02-02 02:55:37,825 Se Vende Blusas,con Delibery Gratis !!\n",
      "2023-02-02 02:55:37,825 Item 171 scrapeado con 茅xito\n",
      "2023-02-02 02:55:39,863 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:39,865 Scrapeando item 172\n",
      "2023-02-02 02:55:45,006 Tacos de verano\n",
      "2023-02-02 02:55:45,006 Item 172 scrapeado con 茅xito\n",
      "2023-02-02 02:55:47,041 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:47,043 Scrapeando item 173\n",
      "2023-02-02 02:55:52,334 Venta de uniformes de senati\n",
      "2023-02-02 02:55:52,349 Item 173 scrapeado con 茅xito\n",
      "2023-02-02 02:55:54,379 -------------------------------------------------------------------\n",
      "2023-02-02 02:55:54,380 Scrapeando item 174\n",
      "2023-02-02 02:55:59,614 Ribriten\n",
      "2023-02-02 02:55:59,614 Item 174 scrapeado con 茅xito\n",
      "2023-02-02 02:56:01,653 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:01,653 Scrapeando item 175\n",
      "2023-02-02 02:56:06,863 Sandalias de lazo \n",
      "2023-02-02 02:56:06,863 Item 175 scrapeado con 茅xito\n",
      "2023-02-02 02:56:08,910 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:08,910 Scrapeando item 176\n",
      "2023-02-02 02:56:14,063 Medias\n",
      "2023-02-02 02:56:14,063 Item 176 scrapeado con 茅xito\n",
      "2023-02-02 02:56:16,105 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:16,106 Scrapeando item 177\n",
      "2023-02-02 02:56:21,309 En Venta Este Vestido Talla 24 .Mese\n",
      "2023-02-02 02:56:21,309 Item 177 scrapeado con 茅xito\n",
      "2023-02-02 02:56:23,342 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:23,342 Scrapeando item 178\n",
      "2023-02-02 02:56:28,502  Hermosos Y Comodos Calzados \n",
      "2023-02-02 02:56:28,502 Item 178 scrapeado con 茅xito\n",
      "2023-02-02 02:56:30,534 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:30,534 Scrapeando item 179\n",
      "2023-02-02 02:56:35,701 Moda\n",
      "2023-02-02 02:56:35,701 Item 179 scrapeado con 茅xito\n",
      "2023-02-02 02:56:37,743 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:37,743 Scrapeando item 180\n",
      "2023-02-02 02:56:42,920 CROP BIBID SPIDER HEART\n",
      "2023-02-02 02:56:42,920 Item 180 scrapeado con 茅xito\n",
      "2023-02-02 02:56:44,965 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:44,965 Scrapeando item 181\n",
      "2023-02-02 02:56:50,125 Maxivestido para chicas lindas\n",
      "2023-02-02 02:56:50,125 Item 181 scrapeado con 茅xito\n",
      "2023-02-02 02:56:58,220 -------------------------------------------------------------------\n",
      "2023-02-02 02:56:58,220 Scrapeando item 182\n",
      "2023-02-02 02:57:03,443 Bodys En Algod贸n Pima\n",
      "2023-02-02 02:57:03,443 Item 182 scrapeado con 茅xito\n",
      "2023-02-02 02:57:05,488 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:05,488 Scrapeando item 183\n",
      "2023-02-02 02:57:10,647 Pantalones mezclilla  licrado Slim fit\n",
      "2023-02-02 02:57:10,647 Item 183 scrapeado con 茅xito\n",
      "2023-02-02 02:57:12,693 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:12,693 Scrapeando item 184\n",
      "2023-02-02 02:57:17,850 BELLOS ABRIGOS PARA DAMA EN TELA PELUCHE \n",
      "2023-02-02 02:57:17,850 Item 184 scrapeado con 茅xito\n",
      "2023-02-02 02:57:19,900 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:19,900 Scrapeando item 185\n",
      "2023-02-02 02:57:25,065 わグBELLO VESTIDO DENIN PARA CHICAS ぉ硷\n",
      "2023-02-02 02:57:25,065 Item 185 scrapeado con 茅xito\n",
      "2023-02-02 02:57:27,108 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:27,108 Scrapeando item 186\n",
      "2023-02-02 02:57:32,395 Shores\n",
      "2023-02-02 02:57:32,395 Item 186 scrapeado con 茅xito\n",
      "2023-02-02 02:57:34,433 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:34,433 Scrapeando item 187\n",
      "2023-02-02 02:57:39,625 Remato sandalias verano T7 y T8\n",
      "2023-02-02 02:57:39,625 Item 187 scrapeado con 茅xito\n",
      "2023-02-02 02:57:41,669 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:41,670 Scrapeando item 188\n",
      "2023-02-02 02:57:46,824 Polos Jersey 30/1 reactivo\n",
      "2023-02-02 02:57:46,824 Item 188 scrapeado con 茅xito\n",
      "2023-02-02 02:57:48,867 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:48,869 Scrapeando item 189\n",
      "2023-02-02 02:57:54,019 Bividis Por Mayor Y Menor\n",
      "2023-02-02 02:57:54,019 Item 189 scrapeado con 茅xito\n",
      "2023-02-02 02:57:56,056 -------------------------------------------------------------------\n",
      "2023-02-02 02:57:56,056 Scrapeando item 190\n",
      "2023-02-02 02:58:01,222 Zapatillas con taco incorporados \n",
      "2023-02-02 02:58:01,222 Item 190 scrapeado con 茅xito\n",
      "2023-02-02 02:58:03,255 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:03,255 Scrapeando item 191\n",
      "2023-02-02 02:58:08,438 Vestido minnie golden\n",
      "2023-02-02 02:58:08,438 Item 191 scrapeado con 茅xito\n",
      "2023-02-02 02:58:10,470 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:10,471 Scrapeando item 192\n",
      "2023-02-02 02:58:15,715 Vestido Negro elegante. Europeo\n",
      "2023-02-02 02:58:15,715 Item 192 scrapeado con 茅xito\n",
      "2023-02-02 02:58:17,747 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:17,747 Scrapeando item 193\n",
      "2023-02-02 02:58:22,903 Sandalias para Damas グ\n",
      "2023-02-02 02:58:22,903 Item 193 scrapeado con 茅xito\n",
      "2023-02-02 02:58:24,937 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:24,937 Scrapeando item 194\n",
      "2023-02-02 02:58:30,175 REMATE DE SHORT NUEVO DRILL COLOR CELESTE TALLA 30 ぉ\n",
      "2023-02-02 02:58:30,175 Item 194 scrapeado con 茅xito\n",
      "2023-02-02 02:58:32,212 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:32,212 Scrapeando item 195\n",
      "2023-02-02 02:58:37,384 ZAPATILLAS DE HOMBRE\n",
      "2023-02-02 02:58:37,384 Item 195 scrapeado con 茅xito\n",
      "2023-02-02 02:58:39,420 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:39,420 Scrapeando item 196\n",
      "2023-02-02 02:58:44,618 SET ESCOLAR TINKERBELL\n",
      "2023-02-02 02:58:44,618 Item 196 scrapeado con 茅xito\n",
      "2023-02-02 02:58:46,648 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:46,649 Scrapeando item 197\n",
      "2023-02-02 02:58:51,847 CONJUNTOS DE NIOS PARA EL VERANO\n",
      "2023-02-02 02:58:51,847 Item 197 scrapeado con 茅xito\n",
      "2023-02-02 02:58:53,878 -------------------------------------------------------------------\n",
      "2023-02-02 02:58:53,880 Scrapeando item 198\n",
      "2023-02-02 02:58:59,046 Bellas sandalias para Damas \n",
      "2023-02-02 02:58:59,046 Item 198 scrapeado con 茅xito\n",
      "2023-02-02 02:59:01,077 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:01,077 Scrapeando item 199\n",
      "2023-02-02 02:59:06,242 Camiseta Sporting Cristal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 02:59:06,242 Item 199 scrapeado con 茅xito\n",
      "2023-02-02 02:59:08,275 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:08,279 Scrapeando item 200\n",
      "2023-02-02 02:59:13,541 Polos Juvenil S M L Pima わ\n",
      "2023-02-02 02:59:13,541 Item 200 scrapeado con 茅xito\n",
      "2023-02-02 02:59:15,575 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:15,576 Scrapeando item 201\n",
      "2023-02-02 02:59:20,727 Ropa de bebe Ni帽a\n",
      "0 - 6 meses\n",
      "2023-02-02 02:59:20,727 Item 201 scrapeado con 茅xito\n",
      "2023-02-02 02:59:22,769 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:22,770 Scrapeando item 202\n",
      "2023-02-02 02:59:27,946 Jogger cuerina\n",
      "2023-02-02 02:59:27,946 Item 202 scrapeado con 茅xito\n",
      "2023-02-02 02:59:29,982 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:29,983 Scrapeando item 203\n",
      "2023-02-02 02:59:35,138 Vestido Jean Moderno\n",
      "2023-02-02 02:59:35,138 Item 203 scrapeado con 茅xito\n",
      "2023-02-02 02:59:37,168 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:37,169 Scrapeando item 204\n",
      "2023-02-02 02:59:42,312 Borcegu铆e T谩ctico Acolchado\n",
      "2023-02-02 02:59:42,312 Item 204 scrapeado con 茅xito\n",
      "2023-02-02 02:59:50,413 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:50,413 Scrapeando item 205\n",
      "2023-02-02 02:59:55,584 Sandalias Hermosas de verano \n",
      "2023-02-02 02:59:55,584 Item 205 scrapeado con 茅xito\n",
      "2023-02-02 02:59:57,616 -------------------------------------------------------------------\n",
      "2023-02-02 02:59:57,618 Scrapeando item 206\n",
      "2023-02-02 03:00:02,774 CONJUNTOS PARA NIOS DE VERANO\n",
      "2023-02-02 03:00:02,774 Item 206 scrapeado con 茅xito\n",
      "2023-02-02 03:00:04,812 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:04,812 Scrapeando item 207\n",
      "2023-02-02 03:00:09,972 Ropitas de ni帽a\n",
      "2023-02-02 03:00:09,972 Item 207 scrapeado con 茅xito\n",
      "2023-02-02 03:00:12,005 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:12,007 Scrapeando item 208\n",
      "2023-02-02 03:00:17,174 CHOMPAS RAYAS & JASPEADA\n",
      "2023-02-02 03:00:17,174 Item 208 scrapeado con 茅xito\n",
      "2023-02-02 03:00:19,226 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:19,226 Scrapeando item 209\n",
      "2023-02-02 03:00:24,397 ZAPATILLAS ORIGINALES (leer descripci贸n)\n",
      "2023-02-02 03:00:24,397 Item 209 scrapeado con 茅xito\n",
      "2023-02-02 03:00:26,451 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:26,451 Scrapeando item 210\n",
      "2023-02-02 03:00:31,637 SHORTS PINZAS PARA CHICAS \n",
      "2023-02-02 03:00:31,637 Item 210 scrapeado con 茅xito\n",
      "2023-02-02 03:00:33,681 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:33,682 Scrapeando item 211\n",
      "2023-02-02 03:00:38,841 Hermosas Sandalias  Tendencia 2023\n",
      "2023-02-02 03:00:38,841 Item 211 scrapeado con 茅xito\n",
      "2023-02-02 03:00:40,886 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:40,887 Scrapeando item 212\n",
      "2023-02-02 03:00:46,042 Camisa de Ni帽o de 2da remate\n",
      "2023-02-02 03:00:46,042 Item 212 scrapeado con 茅xito\n",
      "2023-02-02 03:00:48,077 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:48,078 Scrapeando item 213\n",
      "2023-02-02 03:00:53,234 Jeans Marca  T O R E T T O \n",
      "2023-02-02 03:00:53,234 Item 213 scrapeado con 茅xito\n",
      "2023-02-02 03:00:55,268 -------------------------------------------------------------------\n",
      "2023-02-02 03:00:55,269 Scrapeando item 214\n",
      "2023-02-02 03:01:00,439 Pijama Penguin original nueva de hombre\n",
      "2023-02-02 03:01:00,439 Item 214 scrapeado con 茅xito\n",
      "2023-02-02 03:01:02,479 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:02,480 Scrapeando item 215\n",
      "2023-02-02 03:01:07,629 DIVINAS Y BELLAS TENDENCIA \n",
      "2023-02-02 03:01:07,629 Item 215 scrapeado con 茅xito\n",
      "2023-02-02 03:01:09,669 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:09,670 Scrapeando item 216\n",
      "2023-02-02 03:01:14,836 Casaca de Varon\n",
      "2023-02-02 03:01:14,836 Item 216 scrapeado con 茅xito\n",
      "2023-02-02 03:01:16,869 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:16,872 Scrapeando item 217\n",
      "2023-02-02 03:01:22,047 Remate Short Guess Original\n",
      "2023-02-02 03:01:22,047 Item 217 scrapeado con 茅xito\n",
      "2023-02-02 03:01:24,083 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:24,084 Scrapeando item 218\n",
      "2023-02-02 03:01:29,228 Vendo Pantal贸n  Jean Desde  La 28 Ala 34 En 45 Soles\n",
      "2023-02-02 03:01:29,228 Item 218 scrapeado con 茅xito\n",
      "2023-02-02 03:01:31,274 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:31,275 Scrapeando item 219\n",
      "2023-02-02 03:01:36,447 Ae\n",
      "2023-02-02 03:01:36,447 Item 219 scrapeado con 茅xito\n",
      "2023-02-02 03:01:38,493 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:38,495 Scrapeando item 220\n",
      "2023-02-02 03:01:43,722 100% CUERO SPROT NUEVOS BOTINES HOMBRES CCAT\n",
      "2023-02-02 03:01:43,722 Item 220 scrapeado con 茅xito\n",
      "2023-02-02 03:01:45,760 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:45,761 Scrapeando item 221\n",
      "2023-02-02 03:01:50,937 Polivestidos de dama \n",
      "2023-02-02 03:01:50,937 Item 221 scrapeado con 茅xito\n",
      "2023-02-02 03:01:52,969 -------------------------------------------------------------------\n",
      "2023-02-02 03:01:52,971 Scrapeando item 222\n",
      "2023-02-02 03:01:58,126 Sandalias para damas\n",
      "2023-02-02 03:01:58,126 Item 222 scrapeado con 茅xito\n",
      "2023-02-02 03:02:00,156 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:00,157 Scrapeando item 223\n",
      "2023-02-02 03:02:05,327 Lindas Zandaliaas Para Dama Talla De La 35 a La 39\n",
      "2023-02-02 03:02:05,327 Item 223 scrapeado con 茅xito\n",
      "2023-02-02 03:02:07,362 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:07,363 Scrapeando item 224\n",
      "2023-02-02 03:02:12,518 Conjunto De Ni帽o\n",
      "2023-02-02 03:02:12,518 Item 224 scrapeado con 茅xito\n",
      "2023-02-02 03:02:14,554 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:14,555 Scrapeando item 225\n",
      "2023-02-02 03:02:19,708 Vestido talla 2\n",
      "2023-02-02 03:02:19,708 Item 225 scrapeado con 茅xito\n",
      "2023-02-02 03:02:21,743 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:21,745 Scrapeando item 226\n",
      "2023-02-02 03:02:26,898 Venta a1##M盲r铆ach茂's##un buen detalle锔 para regalar 叼\n",
      "2023-02-02 03:02:26,898 Item 226 scrapeado con 茅xito\n",
      "2023-02-02 03:02:28,934 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:28,935 Scrapeando item 227\n",
      "2023-02-02 03:02:34,091 SOPORTE MULTIFUNCIONAL\n",
      "2023-02-02 03:02:34,091 Item 227 scrapeado con 茅xito\n",
      "2023-02-02 03:02:36,129 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:36,130 Scrapeando item 228\n",
      "2023-02-02 03:02:41,268 Estiletos mujer\n",
      "2023-02-02 03:02:41,268 Item 228 scrapeado con 茅xito\n",
      "2023-02-02 03:02:49,393 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:49,393 Scrapeando item 229\n",
      "2023-02-02 03:02:54,555 Blusas sat铆n\n",
      "2023-02-02 03:02:54,555 Item 229 scrapeado con 茅xito\n",
      "2023-02-02 03:02:56,584 -------------------------------------------------------------------\n",
      "2023-02-02 03:02:56,586 Scrapeando item 230\n",
      "2023-02-02 03:03:01,724 Lindos Modelos En Sandalias \n",
      "2023-02-02 03:03:01,724 Item 230 scrapeado con 茅xito\n",
      "2023-02-02 03:03:03,761 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:03,763 Scrapeando item 231\n",
      "2023-02-02 03:03:08,908 Botines para mujer\n",
      "2023-02-02 03:03:08,908 Item 231 scrapeado con 茅xito\n",
      "2023-02-02 03:03:10,947 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:10,948 Scrapeando item 232\n",
      "2023-02-02 03:03:16,115 Oferton de botines\n",
      "2023-02-02 03:03:16,115 Item 232 scrapeado con 茅xito\n",
      "2023-02-02 03:03:18,158 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:18,159 Scrapeando item 233\n",
      "2023-02-02 03:03:23,318 Polos Dama\n",
      "2023-02-02 03:03:23,318 Item 233 scrapeado con 茅xito\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 03:03:25,362 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:25,364 Scrapeando item 234\n",
      "2023-02-02 03:03:30,524 LEGGIN AMERICANO ORIGINAL MARCA PINK\n",
      "2023-02-02 03:03:30,524 Item 234 scrapeado con 茅xito\n",
      "2023-02-02 03:03:32,565 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:32,567 Scrapeando item 235\n",
      "2023-02-02 03:03:37,733 Enterizo Short\n",
      "2023-02-02 03:03:37,733 Item 235 scrapeado con 茅xito\n",
      "2023-02-02 03:03:39,763 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:39,764 Scrapeando item 236\n",
      "2023-02-02 03:03:44,912 Lentes de sol para ni帽as\n",
      "2023-02-02 03:03:44,912 Item 236 scrapeado con 茅xito\n",
      "2023-02-02 03:03:46,950 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:46,951 Scrapeando item 237\n",
      "2023-02-02 03:03:52,114 Fabrica de Camisas Hilton\n",
      "2023-02-02 03:03:52,114 Item 237 scrapeado con 茅xito\n",
      "2023-02-02 03:03:54,158 -------------------------------------------------------------------\n",
      "2023-02-02 03:03:54,159 Scrapeando item 238\n",
      "2023-02-02 03:03:59,333 Lindas Sandalias de Temporada para Ni帽as - Modelos exclusivos  \n",
      "2023-02-02 03:03:59,333 Item 238 scrapeado con 茅xito\n",
      "2023-02-02 03:04:01,376 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:01,377 Scrapeando item 239\n",
      "2023-02-02 03:04:06,526 Chompitas de ni帽a\n",
      "2023-02-02 03:04:06,526 Item 239 scrapeado con 茅xito\n",
      "2023-02-02 03:04:08,556 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:08,558 Scrapeando item 240\n",
      "2023-02-02 03:04:13,802 Poleras y pant harem  para bebe\n",
      "2023-02-02 03:04:13,802 Item 240 scrapeado con 茅xito\n",
      "2023-02-02 03:04:15,841 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:15,842 Scrapeando item 241\n",
      "2023-02-02 03:04:21,177 Polos San Valent铆n\n",
      "2023-02-02 03:04:21,177 Item 241 scrapeado con 茅xito\n",
      "2023-02-02 03:04:23,222 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:23,223 Scrapeando item 242\n",
      "2023-02-02 03:04:28,410 Shores en piel de durazno talla standar\n",
      "2023-02-02 03:04:28,410 Item 242 scrapeado con 茅xito\n",
      "2023-02-02 03:04:30,435 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:30,436 Scrapeando item 243\n",
      "2023-02-02 03:04:35,637 烩HACEMOS SERVICIOS DE PATRONES MOLDES DAMA Y CABALLERO ETC.猸\n",
      "2023-02-02 03:04:35,637 Item 243 scrapeado con 茅xito\n",
      "2023-02-02 03:04:37,662 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:37,663 Scrapeando item 244\n",
      "2023-02-02 03:04:42,884 Closet sale \n",
      "2023-02-02 03:04:42,899 Item 244 scrapeado con 茅xito\n",
      "2023-02-02 03:04:44,934 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:44,935 Scrapeando item 245\n",
      "2023-02-02 03:04:50,185 Falda negra\n",
      "2023-02-02 03:04:50,185 Item 245 scrapeado con 茅xito\n",
      "2023-02-02 03:04:52,211 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:52,212 Scrapeando item 246\n",
      "2023-02-02 03:04:57,430 Jeans argolla\n",
      "2023-02-02 03:04:57,430 Item 246 scrapeado con 茅xito\n",
      "2023-02-02 03:04:59,469 -------------------------------------------------------------------\n",
      "2023-02-02 03:04:59,470 Scrapeando item 247\n",
      "2023-02-02 03:05:04,700 Hermosos zapatos de charol marca FOOTLOOSE\n",
      "2023-02-02 03:05:04,700 Item 247 scrapeado con 茅xito\n",
      "2023-02-02 03:05:06,742 -------------------------------------------------------------------\n",
      "2023-02-02 03:05:06,743 Scrapeando item 248\n",
      "2023-02-02 03:05:11,913 Casacas crop \n",
      "2023-02-02 03:05:11,913 Item 248 scrapeado con 茅xito\n",
      "2023-02-02 03:05:13,947 -------------------------------------------------------------------\n",
      "2023-02-02 03:05:13,948 Scrapeando item 249\n",
      "2023-02-02 03:05:19,160 Vestido Ni帽a talla 5\n",
      "2023-02-02 03:05:19,160 Item 249 scrapeado con 茅xito\n",
      "2023-02-02 03:05:21,187 -------------------------------------------------------------------\n",
      "2023-02-02 03:05:21,190 Scrapeando item 250\n",
      "2023-02-02 03:05:26,374 Hermosa Camisa americana original marca STAFFORD\n",
      "2023-02-02 03:05:26,374 Item 250 scrapeado con 茅xito\n",
      "2023-02-02 03:05:28,408 -------------------------------------------------------------------\n",
      "2023-02-02 03:05:28,409 Scrapeando item 251\n",
      "2023-02-02 03:05:33,571 Vestido Para damas\n",
      "2023-02-02 03:05:33,586 Item 251 scrapeado con 茅xito\n",
      "2023-02-02 03:05:35,620 -------------------------------------------------------------------\n",
      "2023-02-02 03:05:35,621 Scrapeando item 252\n",
      "2023-02-02 03:05:40,797 Vestido ni帽a talla 4/5 a帽os\n",
      "2023-02-02 03:05:40,797 Item 252 scrapeado con 茅xito\n",
      "2023-02-02 03:05:48,905 -------------------------------------------------------------------\n",
      "2023-02-02 03:05:48,905 Scrapeando item 253\n",
      "2023-02-02 03:05:54,098 Polo de algod贸n de PUNTA CANA\n",
      "2023-02-02 03:05:54,098 Item 253 scrapeado con 茅xito\n",
      "2023-02-02 03:05:56,139 -------------------------------------------------------------------\n",
      "2023-02-02 03:05:56,141 Scrapeando item 254\n",
      "2023-02-02 03:06:01,310 Poncho Impermeable Para Lluvia Capa Viaje Hombre Mujer\n",
      "2023-02-02 03:06:01,310 Item 254 scrapeado con 茅xito\n",
      "2023-02-02 03:06:03,345 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:03,346 Scrapeando item 255\n",
      "2023-02-02 03:06:08,501 CAMISETA ALIANZA LIMA OFICIAL\n",
      "2023-02-02 03:06:08,501 Item 255 scrapeado con 茅xito\n",
      "2023-02-02 03:06:10,539 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:10,540 Scrapeando item 256\n",
      "2023-02-02 03:06:15,717 POLITOS BONITOS PARA CHICAS\n",
      "2023-02-02 03:06:15,717 Item 256 scrapeado con 茅xito\n",
      "2023-02-02 03:06:17,744 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:17,745 Scrapeando item 257\n",
      "2023-02-02 03:06:22,941 Se vende Vestido de ni帽a en buen Estado\n",
      "2023-02-02 03:06:22,941 Item 257 scrapeado con 茅xito\n",
      "2023-02-02 03:06:24,968 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:24,970 Scrapeando item 258\n",
      "2023-02-02 03:06:30,159 Short de entrenamiento impermeable\n",
      "2023-02-02 03:06:30,159 Item 258 scrapeado con 茅xito\n",
      "2023-02-02 03:06:32,200 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:32,201 Scrapeando item 259\n",
      "2023-02-02 03:06:37,396 Chompita de bebe 6 meses\n",
      "2023-02-02 03:06:37,396 Item 259 scrapeado con 茅xito\n",
      "2023-02-02 03:06:39,435 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:39,436 Scrapeando item 260\n",
      "2023-02-02 03:06:44,603 Hermoso Bivid铆 americano de ILLINOIS\n",
      "2023-02-02 03:06:44,603 Item 260 scrapeado con 茅xito\n",
      "2023-02-02 03:06:46,645 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:46,646 Scrapeando item 261\n",
      "2023-02-02 03:06:51,804 Zapatos de colegio de ni帽a talla 38 \n",
      "2023-02-02 03:06:51,804 Item 261 scrapeado con 茅xito\n",
      "2023-02-02 03:06:53,836 -------------------------------------------------------------------\n",
      "2023-02-02 03:06:53,837 Scrapeando item 262\n",
      "2023-02-02 03:06:58,988 Polo americano original marca UNDER ARMOUR\n",
      "2023-02-02 03:06:58,988 Item 262 scrapeado con 茅xito\n",
      "2023-02-02 03:07:01,026 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:01,028 Scrapeando item 263\n",
      "2023-02-02 03:07:06,189 ROPA DE BEBE VARON\n",
      "2023-02-02 03:07:06,189 Item 263 scrapeado con 茅xito\n",
      "2023-02-02 03:07:08,222 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:08,224 Scrapeando item 264\n",
      "2023-02-02 03:07:13,368 Hermosas sandalias de fiesta Plateadas\n",
      "2023-02-02 03:07:13,368 Item 264 scrapeado con 茅xito\n",
      "2023-02-02 03:07:15,407 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:15,409 Scrapeando item 265\n",
      "2023-02-02 03:07:20,613 Polo americano original marca PINK\n",
      "2023-02-02 03:07:20,613 Item 265 scrapeado con 茅xito\n",
      "2023-02-02 03:07:22,640 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:22,641 Scrapeando item 266\n",
      "2023-02-02 03:07:27,858 Pantal贸n, palazo\n",
      "2023-02-02 03:07:27,858 Item 266 scrapeado con 茅xito\n",
      "2023-02-02 03:07:29,896 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:29,898 Scrapeando item 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 03:07:35,076 Falvas Envolventes Largas \n",
      "2023-02-02 03:07:35,076 Item 267 scrapeado con 茅xito\n",
      "2023-02-02 03:07:37,117 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:37,118 Scrapeando item 268\n",
      "2023-02-02 03:07:42,323 Sandalias\n",
      "2023-02-02 03:07:42,323 Item 268 scrapeado con 茅xito\n",
      "2023-02-02 03:07:44,356 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:44,358 Scrapeando item 269\n",
      "2023-02-02 03:07:49,541 Hermosos TOPS s煤per frescos\n",
      "2023-02-02 03:07:49,543 Item 269 scrapeado con 茅xito\n",
      "2023-02-02 03:07:51,567 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:51,569 Scrapeando item 270\n",
      "2023-02-02 03:07:56,750 Conjunto\n",
      "2023-02-02 03:07:56,751 Item 270 scrapeado con 茅xito\n",
      "2023-02-02 03:07:58,779 -------------------------------------------------------------------\n",
      "2023-02-02 03:07:58,780 Scrapeando item 271\n",
      "2023-02-02 03:08:03,983 Tacones De Vestir en tallas y colores\n",
      "2023-02-02 03:08:03,983 Item 271 scrapeado con 茅xito\n",
      "2023-02-02 03:08:06,020 -------------------------------------------------------------------\n",
      "2023-02-02 03:08:06,022 Scrapeando item 272\n",
      "2023-02-02 03:08:11,200 Denim Jean\n",
      "2023-02-02 03:08:11,200 Item 272 scrapeado con 茅xito\n",
      "2023-02-02 03:08:13,239 -------------------------------------------------------------------\n",
      "2023-02-02 03:08:13,240 Scrapeando item 273\n",
      "2023-02-02 03:08:18,416 HERMOSOS VESTIDOS DE TEMPORADA AL POR MAYOR \n",
      "2023-02-02 03:08:18,416 Item 273 scrapeado con 茅xito\n",
      "2023-02-02 03:08:20,443 -------------------------------------------------------------------\n",
      "2023-02-02 03:08:20,444 Scrapeando item 274\n",
      "2023-02-02 03:08:25,655 Sandalias De Ni帽o Talla 22\n",
      "2023-02-02 03:08:25,655 Item 274 scrapeado con 茅xito\n",
      "2023-02-02 03:08:33,771 -------------------------------------------------------------------\n",
      "2023-02-02 03:08:33,771 Scrapeando item 275\n",
      "2023-02-02 03:08:38,980 BUZO + SHORT\n",
      "2023-02-02 03:08:38,980 Item 275 scrapeado con 茅xito\n",
      "2023-02-02 03:08:41,032 -------------------------------------------------------------------\n",
      "2023-02-02 03:08:41,033 Scrapeando item 276\n",
      "2023-02-02 03:08:46,232 PANTALON JEANS DE MUJER \n",
      "2023-02-02 03:08:46,232 Item 276 scrapeado con 茅xito\n",
      "2023-02-02 03:08:48,269 -------------------------------------------------------------------\n",
      "2023-02-02 03:08:48,270 Scrapeando item 277\n",
      "2023-02-02 03:08:53,493 Enterizo\n",
      "2023-02-02 03:08:53,493 Item 277 scrapeado con 茅xito\n",
      "2023-02-02 03:08:55,531 -------------------------------------------------------------------\n",
      "2023-02-02 03:08:55,533 Scrapeando item 278\n",
      "2023-02-02 03:09:00,708 Camisas verano para perritos 垛ワ\n",
      "2023-02-02 03:09:00,708 Item 278 scrapeado con 茅xito\n",
      "2023-02-02 03:09:02,743 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:02,744 Scrapeando item 279\n",
      "2023-02-02 03:09:07,924 FALDA ESCOCESA わ\n",
      "2023-02-02 03:09:07,924 Item 279 scrapeado con 茅xito\n",
      "2023-02-02 03:09:09,959 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:09,960 Scrapeando item 280\n",
      "2023-02-02 03:09:15,159 Hermoso conjunto vestido para beb茅s y ni帽as\n",
      "2023-02-02 03:09:15,159 Item 280 scrapeado con 茅xito\n",
      "2023-02-02 03:09:17,191 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:17,193 Scrapeando item 281\n",
      "2023-02-02 03:09:22,383 BLUSA UN CLASICO PARA TU CLSET\n",
      "2023-02-02 03:09:22,383 Item 281 scrapeado con 茅xito\n",
      "2023-02-02 03:09:24,415 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:24,417 Scrapeando item 282\n",
      "2023-02-02 03:09:29,610 Leggins latex tallas\n",
      "2023-02-02 03:09:29,610 Item 282 scrapeado con 茅xito\n",
      "2023-02-02 03:09:31,634 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:31,635 Scrapeando item 283\n",
      "2023-02-02 03:09:36,847 Vestido negro talla S Michele belau\n",
      "2023-02-02 03:09:36,847 Item 283 scrapeado con 茅xito\n",
      "2023-02-02 03:09:38,879 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:38,880 Scrapeando item 284\n",
      "2023-02-02 03:09:44,083 Ventas de conjuntos m茅dicos\n",
      "2023-02-02 03:09:44,083 Item 284 scrapeado con 茅xito\n",
      "2023-02-02 03:09:46,119 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:46,121 Scrapeando item 285\n",
      "2023-02-02 03:09:51,332 MALETA Y LONCHERA DE PRINCESAS DISNEY\n",
      "2023-02-02 03:09:51,332 Item 285 scrapeado con 茅xito\n",
      "2023-02-02 03:09:53,367 -------------------------------------------------------------------\n",
      "2023-02-02 03:09:53,367 Scrapeando item 286\n",
      "2023-02-02 03:09:58,566 Vestidos Importados Minnie mouse y Encanto Isabella\n",
      "2023-02-02 03:09:58,566 Item 286 scrapeado con 茅xito\n",
      "2023-02-02 03:10:00,593 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:00,595 Scrapeando item 287\n",
      "2023-02-02 03:10:05,795 Blusa a cuadros fucsia talla M\n",
      "2023-02-02 03:10:05,795 Item 287 scrapeado con 茅xito\n",
      "2023-02-02 03:10:07,835 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:07,836 Scrapeando item 288\n",
      "2023-02-02 03:10:13,044 Vendo zapatos para primera comuni贸nSECOND HAND\n",
      "2023-02-02 03:10:13,044 Item 288 scrapeado con 茅xito\n",
      "2023-02-02 03:10:15,073 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:15,074 Scrapeando item 289\n",
      "2023-02-02 03:10:20,343 Stilettos Steve Madden 6 1/2\n",
      "2023-02-02 03:10:20,359 Item 289 scrapeado con 茅xito\n",
      "2023-02-02 03:10:22,379 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:22,380 Scrapeando item 290\n",
      "2023-02-02 03:10:27,615 Ropa de beb茅\n",
      "2023-02-02 03:10:27,615 Item 290 scrapeado con 茅xito\n",
      "2023-02-02 03:10:29,655 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:29,656 Scrapeando item 291\n",
      "2023-02-02 03:10:34,925 Calzado Ni帽a\n",
      "2023-02-02 03:10:34,925 Item 291 scrapeado con 茅xito\n",
      "2023-02-02 03:10:36,963 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:36,964 Scrapeando item 292\n",
      "2023-02-02 03:10:42,228 Remato carteras para ni帽as\n",
      "2023-02-02 03:10:42,228 Item 292 scrapeado con 茅xito\n",
      "2023-02-02 03:10:44,258 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:44,259 Scrapeando item 293\n",
      "2023-02-02 03:10:49,529 Bellas  y comodas sandalias para damas\n",
      "2023-02-02 03:10:49,529 Item 293 scrapeado con 茅xito\n",
      "2023-02-02 03:10:51,563 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:51,564 Scrapeando item 294\n",
      "2023-02-02 03:10:56,829 Conjunto\n",
      "2023-02-02 03:10:56,829 Item 294 scrapeado con 茅xito\n",
      "2023-02-02 03:10:58,856 -------------------------------------------------------------------\n",
      "2023-02-02 03:10:58,858 Scrapeando item 295\n",
      "2023-02-02 03:11:04,100 Pantalones Palazos Piel De Durazno\n",
      "2023-02-02 03:11:04,100 Item 295 scrapeado con 茅xito\n",
      "2023-02-02 03:11:06,128 -------------------------------------------------------------------\n",
      "2023-02-02 03:11:06,130 Scrapeando item 296\n",
      "2023-02-02 03:11:11,393 CASACAS PUFFER CROP DELIVERY GRATIS A SU DOMICILIO \n",
      "2023-02-02 03:11:11,393 Item 296 scrapeado con 茅xito\n",
      "2023-02-02 03:11:13,424 -------------------------------------------------------------------\n",
      "2023-02-02 03:11:13,425 Scrapeando item 297\n",
      "2023-02-02 03:11:18,757 SHORTS Y POLOS \n",
      "2023-02-02 03:11:18,757 Item 297 scrapeado con 茅xito\n",
      "2023-02-02 03:11:20,787 -------------------------------------------------------------------\n",
      "2023-02-02 03:11:20,788 Scrapeando item 298\n",
      "2023-02-02 03:11:26,082 Maniqu铆es De Alta Costura ,de Dama Elegantes Para Exhibir Y Confeccionar\n",
      "2023-02-02 03:11:26,082 Item 298 scrapeado con 茅xito\n",
      "2023-02-02 03:11:34,188 -------------------------------------------------------------------\n",
      "2023-02-02 03:11:34,188 Scrapeando item 299\n",
      "2023-02-02 03:11:39,620 Zapatos de mujer negro\n",
      "2023-02-02 03:11:39,622 Item 299 scrapeado con 茅xito\n",
      "2023-02-02 03:11:41,646 -------------------------------------------------------------------\n",
      "2023-02-02 03:11:41,648 Scrapeando item 300\n",
      "2023-02-02 03:11:46,851 Zapato De Colegio\n",
      "2023-02-02 03:11:46,853 Item 300 scrapeado con 茅xito\n",
      "2023-02-02 03:11:48,887 -------------------------------------------------------------------\n",
      "2023-02-02 03:11:48,889 Scrapeando item 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 03:11:54,064 Sandalias\n",
      "2023-02-02 03:11:54,064 Item 301 scrapeado con 茅xito\n",
      "2023-02-02 03:11:56,099 -------------------------------------------------------------------\n",
      "2023-02-02 03:11:56,100 Scrapeando item 302\n",
      "2023-02-02 03:12:01,303 Sandalia de cuero\n",
      "2023-02-02 03:12:01,303 Item 302 scrapeado con 茅xito\n",
      "2023-02-02 03:12:03,352 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:03,353 Scrapeando item 303\n",
      "2023-02-02 03:12:08,558 Casaca de b茅isbol RED SOX para ni帽o T/ 7\n",
      "2023-02-02 03:12:08,558 Item 303 scrapeado con 茅xito\n",
      "2023-02-02 03:12:10,597 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:10,598 Scrapeando item 304\n",
      "2023-02-02 03:12:15,812 Terno De Ni帽o Blanco\n",
      "2023-02-02 03:12:15,812 Item 304 scrapeado con 茅xito\n",
      "2023-02-02 03:12:17,844 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:17,846 Scrapeando item 305\n",
      "2023-02-02 03:12:23,037 Polos gapnuevos s-m\n",
      "2023-02-02 03:12:23,037 Item 305 scrapeado con 茅xito\n",
      "2023-02-02 03:12:25,063 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:25,064 Scrapeando item 306\n",
      "2023-02-02 03:12:30,253 Chevrolet trucks 1955 Oferta polo cl谩sico\n",
      "2023-02-02 03:12:30,253 Item 306 scrapeado con 茅xito\n",
      "2023-02-02 03:12:32,289 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:32,290 Scrapeando item 307\n",
      "2023-02-02 03:12:37,478 CONJUNTO\n",
      "2023-02-02 03:12:37,478 Item 307 scrapeado con 茅xito\n",
      "2023-02-02 03:12:39,515 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:39,516 Scrapeando item 308\n",
      "2023-02-02 03:12:44,694 Closet sale Nina Talla 3-4\n",
      "2023-02-02 03:12:44,694 Item 308 scrapeado con 茅xito\n",
      "2023-02-02 03:12:46,721 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:46,722 Scrapeando item 309\n",
      "2023-02-02 03:12:51,918 ワ LINDOS BODYS SUPER HEROES..NIA Y NIO. ワ\n",
      "2023-02-02 03:12:51,918 Item 309 scrapeado con 茅xito\n",
      "2023-02-02 03:12:53,949 -------------------------------------------------------------------\n",
      "2023-02-02 03:12:53,950 Scrapeando item 310\n",
      "2023-02-02 03:12:59,156 Sandalias Ipanema\n",
      "2023-02-02 03:12:59,156 Item 310 scrapeado con 茅xito\n",
      "2023-02-02 03:13:01,188 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:01,188 Scrapeando item 311\n",
      "2023-02-02 03:13:06,389 zapatos vizzano\n",
      "2023-02-02 03:13:06,389 Item 311 scrapeado con 茅xito\n",
      "2023-02-02 03:13:08,429 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:08,430 Scrapeando item 312\n",
      "2023-02-02 03:13:13,636 Venta o alquiler de 2 vestidos para damitas, talla S O M\n",
      "2023-02-02 03:13:13,636 Item 312 scrapeado con 茅xito\n",
      "2023-02-02 03:13:15,668 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:15,669 Scrapeando item 313\n",
      "2023-02-02 03:13:21,049 Poncho Impermeable Para Lluvia Capa Viaje Hombre Mujer\n",
      "2023-02-02 03:13:21,065 Item 313 scrapeado con 茅xito\n",
      "2023-02-02 03:13:23,099 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:23,101 Scrapeando item 314\n",
      "2023-02-02 03:13:28,336 Ropa De Bebe Organica  Venta Por Paquete 20 Piesas  300 Soles   Mensajes Wasat [hidden information] .\n",
      "2023-02-02 03:13:28,336 Item 314 scrapeado con 茅xito\n",
      "2023-02-02 03:13:30,373 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:30,374 Scrapeando item 315\n",
      "2023-02-02 03:13:35,580 Polos de hombres\n",
      "2023-02-02 03:13:35,580 Item 315 scrapeado con 茅xito\n",
      "2023-02-02 03:13:37,614 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:37,616 Scrapeando item 316\n",
      "2023-02-02 03:13:42,825 Bombero traje contra incendio\n",
      "2023-02-02 03:13:42,825 Item 316 scrapeado con 茅xito\n",
      "2023-02-02 03:13:44,858 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:44,860 Scrapeando item 317\n",
      "2023-02-02 03:13:50,110 Sandalias taco 5\n",
      "2023-02-02 03:13:50,110 Item 317 scrapeado con 茅xito\n",
      "2023-02-02 03:13:52,142 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:52,143 Scrapeando item 318\n",
      "2023-02-02 03:13:57,392 Jeans FAJEROS \n",
      "2023-02-02 03:13:57,392 Item 318 scrapeado con 茅xito\n",
      "2023-02-02 03:13:59,433 -------------------------------------------------------------------\n",
      "2023-02-02 03:13:59,434 Scrapeando item 319\n",
      "2023-02-02 03:14:04,645 NUEVO COLOR DE CHALECO REDUCTOR TERMICO DE MUJER\n",
      "2023-02-02 03:14:04,645 Item 319 scrapeado con 茅xito\n",
      "2023-02-02 03:14:06,681 -------------------------------------------------------------------\n",
      "2023-02-02 03:14:06,682 Scrapeando item 320\n",
      "2023-02-02 03:14:11,931 VESTIDO RIB AMERICANO\n",
      "2023-02-02 03:14:11,931 Item 320 scrapeado con 茅xito\n",
      "2023-02-02 03:14:13,960 -------------------------------------------------------------------\n",
      "2023-02-02 03:14:13,961 Scrapeando item 321\n",
      "2023-02-02 03:14:19,183 PANTUFLAS PARA MUJER DE DISNEY\n",
      "2023-02-02 03:14:19,183 Item 321 scrapeado con 茅xito\n",
      "2023-02-02 03:14:27,330 -------------------------------------------------------------------\n",
      "2023-02-02 03:14:27,330 Scrapeando item 322\n",
      "2023-02-02 03:14:34,509 -------------------------------------------------------------------\n",
      "2023-02-02 03:14:34,510 Scrapeando item 323\n",
      "2023-02-02 03:14:39,765 Polos Algod贸n\n",
      "2023-02-02 03:14:39,765 Item 323 scrapeado con 茅xito\n",
      "2023-02-02 03:14:41,798 -------------------------------------------------------------------\n",
      "2023-02-02 03:14:41,799 Scrapeando item 324\n",
      "2023-02-02 03:14:47,032 Botas de Puro Cuero\n",
      "2023-02-02 03:14:47,032 Item 324 scrapeado con 茅xito\n",
      "2023-02-02 03:14:49,067 -------------------------------------------------------------------\n",
      "2023-02-02 03:14:49,068 Scrapeando item 325\n",
      "2023-02-02 03:14:54,319 Camisas lino de verano por mayor y menor\n",
      "2023-02-02 03:14:54,319 Item 325 scrapeado con 茅xito\n",
      "2023-02-02 03:14:56,355 -------------------------------------------------------------------\n",
      "2023-02-02 03:14:56,356 Scrapeando item 326\n",
      "2023-02-02 03:15:01,699 Casaca Reversible impermeable importadas\n",
      "2023-02-02 03:15:01,699 Item 326 scrapeado con 茅xito\n",
      "2023-02-02 03:15:03,738 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:03,739 Scrapeando item 327\n",
      "2023-02-02 03:15:08,974 Lote de ropa de ni帽a 9 a12 meses\n",
      "2023-02-02 03:15:08,974 Item 327 scrapeado con 茅xito\n",
      "2023-02-02 03:15:11,012 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:11,012 Scrapeando item 328\n",
      "2023-02-02 03:15:16,208 DIVINAS Y BELLAS TENDENCIA JUVENIL \n",
      "2023-02-02 03:15:16,208 Item 328 scrapeado con 茅xito\n",
      "2023-02-02 03:15:18,252 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:18,253 Scrapeando item 329\n",
      "2023-02-02 03:15:23,444 VESTIDO LARGO DE PIEL DE DURAZNO\n",
      "2023-02-02 03:15:23,444 Item 329 scrapeado con 茅xito\n",
      "2023-02-02 03:15:25,481 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:25,483 Scrapeando item 330\n",
      "2023-02-02 03:15:30,672 Uniformes Innova Schools\n",
      "2023-02-02 03:15:30,672 Item 330 scrapeado con 茅xito\n",
      "2023-02-02 03:15:32,720 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:32,721 Scrapeando item 331\n",
      "2023-02-02 03:15:37,921 SHORTS Y POLOS \n",
      "2023-02-02 03:15:37,921 Item 331 scrapeado con 茅xito\n",
      "2023-02-02 03:15:39,964 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:39,965 Scrapeando item 332\n",
      "2023-02-02 03:15:45,185 Pantal贸n Scuba crece\n",
      "2023-02-02 03:15:45,185 Item 332 scrapeado con 茅xito\n",
      "2023-02-02 03:15:47,212 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:47,213 Scrapeando item 333\n",
      "2023-02-02 03:15:52,403 Zapatillas para dama x mayor\n",
      "2023-02-02 03:15:52,403 Item 333 scrapeado con 茅xito\n",
      "2023-02-02 03:15:54,430 -------------------------------------------------------------------\n",
      "2023-02-02 03:15:54,431 Scrapeando item 334\n",
      "2023-02-02 03:15:59,629 Chaqueta para cocina con logo bordado\n",
      "2023-02-02 03:15:59,629 Item 334 scrapeado con 茅xito\n",
      "2023-02-02 03:16:01,667 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:01,668 Scrapeando item 335\n",
      "2023-02-02 03:16:06,860 CASACA OVERSIZE - Streetwear Unisex \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 03:16:06,860 Item 335 scrapeado con 茅xito\n",
      "2023-02-02 03:16:08,898 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:08,900 Scrapeando item 336\n",
      "2023-02-02 03:16:14,097 Sandalias\n",
      "2023-02-02 03:16:14,097 Item 336 scrapeado con 茅xito\n",
      "2023-02-02 03:16:16,126 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:16,128 Scrapeando item 337\n",
      "2023-02-02 03:16:21,348 Vendo vestidos\n",
      "2023-02-02 03:16:21,348 Item 337 scrapeado con 茅xito\n",
      "2023-02-02 03:16:23,375 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:23,376 Scrapeando item 338\n",
      "2023-02-02 03:16:28,622 Vestido chalis xl en chalis premium \n",
      "2023-02-02 03:16:28,622 Item 338 scrapeado con 茅xito\n",
      "2023-02-02 03:16:30,651 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:30,652 Scrapeando item 339\n",
      "2023-02-02 03:16:35,844 Casacas\n",
      "2023-02-02 03:16:35,844 Item 339 scrapeado con 茅xito\n",
      "2023-02-02 03:16:37,878 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:37,879 Scrapeando item 340\n",
      "2023-02-02 03:16:43,111 Pantal贸n\n",
      "2023-02-02 03:16:43,111 Item 340 scrapeado con 茅xito\n",
      "2023-02-02 03:16:45,142 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:45,143 Scrapeando item 341\n",
      "2023-02-02 03:16:50,356 AJUAR DE BEBE OH EMMA RN NUBES ROSA ALGODON PIMA 100%\n",
      "2023-02-02 03:16:50,356 Item 341 scrapeado con 茅xito\n",
      "2023-02-02 03:16:52,393 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:52,394 Scrapeando item 342\n",
      "2023-02-02 03:16:57,581 Zapatos\n",
      "2023-02-02 03:16:57,581 Item 342 scrapeado con 茅xito\n",
      "2023-02-02 03:16:59,617 -------------------------------------------------------------------\n",
      "2023-02-02 03:16:59,618 Scrapeando item 343\n",
      "2023-02-02 03:17:04,781 Vestido de novia\n",
      "2023-02-02 03:17:04,781 Item 343 scrapeado con 茅xito\n",
      "2023-02-02 03:17:06,826 -------------------------------------------------------------------\n",
      "2023-02-02 03:17:06,827 Scrapeando item 344\n",
      "2023-02-02 03:17:12,014 LIQUIDACIN锔锔SOLO POR HOY火锔\n",
      "2023-02-02 03:17:12,015 Item 344 scrapeado con 茅xito\n",
      "2023-02-02 03:17:14,037 -------------------------------------------------------------------\n",
      "2023-02-02 03:17:14,038 Scrapeando item 345\n",
      "2023-02-02 03:17:19,228 粹5Cupos Disponibles\n",
      "2023-02-02 03:17:19,243 Item 345 scrapeado con 茅xito\n",
      "2023-02-02 03:17:21,274 -------------------------------------------------------------------\n",
      "2023-02-02 03:17:21,275 Scrapeando item 346\n",
      "2023-02-02 03:17:26,460 Bellas sandalias de temporada グ\n",
      "2023-02-02 03:17:26,460 Item 346 scrapeado con 茅xito\n",
      "2023-02-02 03:17:34,586 -------------------------------------------------------------------\n",
      "2023-02-02 03:17:34,586 Scrapeando item 347\n",
      "2023-02-02 03:17:39,799 Vestido\n",
      "2023-02-02 03:17:39,799 Item 347 scrapeado con 茅xito\n",
      "2023-02-02 03:17:41,839 -------------------------------------------------------------------\n",
      "2023-02-02 03:17:41,840 Scrapeando item 348\n",
      "2023-02-02 03:17:47,047 Lote de 15 prendas para dama Talla M de segunda (LEER DESCRIPCIN)\n",
      "2023-02-02 03:17:47,047 Item 348 scrapeado con 茅xito\n",
      "2023-02-02 03:17:49,086 -------------------------------------------------------------------\n",
      "2023-02-02 03:17:49,087 Scrapeando item 349\n",
      "2023-02-02 03:17:54,295 Vestidos Algodonю\n",
      "2023-02-02 03:17:54,295 Item 349 scrapeado con 茅xito\n",
      "2023-02-02 03:17:56,325 -------------------------------------------------------------------\n",
      "2023-02-02 03:17:56,327 Scrapeando item 350\n",
      "2023-02-02 03:18:01,510 Vendo polos\n",
      "2023-02-02 03:18:01,526 Item 350 scrapeado con 茅xito\n",
      "2023-02-02 03:18:03,551 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:03,552 Scrapeando item 351\n",
      "2023-02-02 03:18:08,712 Prendas de verano\n",
      "2023-02-02 03:18:08,712 Item 351 scrapeado con 茅xito\n",
      "2023-02-02 03:18:10,759 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:10,760 Scrapeando item 352\n",
      "2023-02-02 03:18:15,939 Polo De Hombre\n",
      "2023-02-02 03:18:15,939 Item 352 scrapeado con 茅xito\n",
      "2023-02-02 03:18:17,968 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:17,969 Scrapeando item 353\n",
      "2023-02-02 03:18:23,143 Zapatillas Mujer\n",
      "2023-02-02 03:18:23,143 Item 353 scrapeado con 茅xito\n",
      "2023-02-02 03:18:25,174 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:25,175 Scrapeando item 354\n",
      "2023-02-02 03:18:30,381 Mochila Barbie\n",
      "2023-02-02 03:18:30,381 Item 354 scrapeado con 茅xito\n",
      "2023-02-02 03:18:32,431 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:32,432 Scrapeando item 355\n",
      "2023-02-02 03:18:37,663 BLUSAS CUELLO NERU SUPER SUAVES Y FRESCAS コ\n",
      "2023-02-02 03:18:37,663 Item 355 scrapeado con 茅xito\n",
      "2023-02-02 03:18:39,690 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:39,691 Scrapeando item 356\n",
      "2023-02-02 03:18:44,904 Botines\n",
      "2023-02-02 03:18:44,904 Item 356 scrapeado con 茅xito\n",
      "2023-02-02 03:18:46,935 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:46,936 Scrapeando item 357\n",
      "2023-02-02 03:18:52,115 А Liquidaci贸n \n",
      "2023-02-02 03:18:52,115 Item 357 scrapeado con 茅xito\n",
      "2023-02-02 03:18:54,158 -------------------------------------------------------------------\n",
      "2023-02-02 03:18:54,159 Scrapeando item 358\n",
      "2023-02-02 03:18:59,383 А SACO SUEDE  А\n",
      "2023-02-02 03:18:59,383 Item 358 scrapeado con 茅xito\n",
      "2023-02-02 03:19:01,409 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:01,411 Scrapeando item 359\n",
      "2023-02-02 03:19:06,634 Casacas largas reversibles para dama\n",
      "2023-02-02 03:19:06,634 Item 359 scrapeado con 茅xito\n",
      "2023-02-02 03:19:08,671 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:08,672 Scrapeando item 360\n",
      "2023-02-02 03:19:13,866 Vestido\n",
      "2023-02-02 03:19:13,866 Item 360 scrapeado con 茅xito\n",
      "2023-02-02 03:19:15,902 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:15,903 Scrapeando item 361\n",
      "2023-02-02 03:19:21,122 Blusa \n",
      "2023-02-02 03:19:21,122 Item 361 scrapeado con 茅xito\n",
      "2023-02-02 03:19:23,153 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:23,154 Scrapeando item 362\n",
      "2023-02-02 03:19:28,365 En venta short licrado y top blanco ワ\n",
      "2023-02-02 03:19:28,365 Item 362 scrapeado con 茅xito\n",
      "2023-02-02 03:19:30,398 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:30,399 Scrapeando item 363\n",
      "2023-02-02 03:19:35,598 Zapatillas\n",
      "2023-02-02 03:19:35,598 Item 363 scrapeado con 茅xito\n",
      "2023-02-02 03:19:37,638 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:37,640 Scrapeando item 364\n",
      "2023-02-02 03:19:42,940 Polos san Valent铆n personalizados\n",
      "2023-02-02 03:19:42,940 Item 364 scrapeado con 茅xito\n",
      "2023-02-02 03:19:44,977 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:44,978 Scrapeando item 365\n",
      "2023-02-02 03:19:50,194 Jeans clasicos\n",
      "2023-02-02 03:19:50,194 Item 365 scrapeado con 茅xito\n",
      "2023-02-02 03:19:52,222 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:52,224 Scrapeando item 366\n",
      "2023-02-02 03:19:57,419 Zapatillas en oferta.\n",
      "Env铆o para Lima y provincia.\n",
      "Se hace delivery y env铆os por agencia\n",
      "2023-02-02 03:19:57,419 Item 366 scrapeado con 茅xito\n",
      "2023-02-02 03:19:59,466 -------------------------------------------------------------------\n",
      "2023-02-02 03:19:59,468 Scrapeando item 367\n",
      "2023-02-02 03:20:04,687 Enterizo short de moda FOREVER21 tallaS\n",
      "吼糕锔\n",
      "2023-02-02 03:20:04,687 Item 367 scrapeado con 茅xito\n",
      "2023-02-02 03:20:06,713 -------------------------------------------------------------------\n",
      "2023-02-02 03:20:06,714 Scrapeando item 368\n",
      "2023-02-02 03:20:11,918 ぉ Hermosas casacas en cuerinaぉ\n",
      "2023-02-02 03:20:11,918 Item 368 scrapeado con 茅xito\n",
      "2023-02-02 03:20:20,054 -------------------------------------------------------------------\n",
      "2023-02-02 03:20:20,054 Scrapeando item 369\n",
      "2023-02-02 03:20:25,309 Polos para dama \n",
      "2023-02-02 03:20:25,309 Item 369 scrapeado con 茅xito\n",
      "2023-02-02 03:20:27,343 -------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 03:20:27,344 Scrapeando item 370\n",
      "2023-02-02 03:20:32,561 Shorer De Dama\n",
      "2023-02-02 03:20:32,561 Item 370 scrapeado con 茅xito\n",
      "2023-02-02 03:20:34,596 -------------------------------------------------------------------\n",
      "2023-02-02 03:20:34,598 Scrapeando item 371\n",
      "2023-02-02 03:20:39,846 Talla XXXXL, XXXL, XXL y XL. Blusas de Chalis. Contraentrega. Delivery a Toda Lima y Callao. Envios\n",
      "2023-02-02 03:20:39,846 Item 371 scrapeado con 茅xito\n",
      "2023-02-02 03:20:41,889 -------------------------------------------------------------------\n",
      "2023-02-02 03:20:41,890 Scrapeando item 372\n",
      "2023-02-02 03:20:47,127 Mango casaca mujer talla M\n",
      "2023-02-02 03:20:47,127 Item 372 scrapeado con 茅xito\n",
      "2023-02-02 03:20:49,158 -------------------------------------------------------------------\n",
      "2023-02-02 03:20:49,160 Scrapeando item 373\n",
      "2023-02-02 03:20:54,359 Botas de seguridad (punta de acero) para dama 封锔\n",
      "2023-02-02 03:20:54,359 Item 373 scrapeado con 茅xito\n",
      "2023-02-02 03:20:56,401 -------------------------------------------------------------------\n",
      "2023-02-02 03:20:56,402 Scrapeando item 374\n",
      "2023-02-02 03:21:01,645 DIVINAS Y BELLAS \n",
      "2023-02-02 03:21:01,645 Item 374 scrapeado con 茅xito\n",
      "2023-02-02 03:21:03,695 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:03,697 Scrapeando item 375\n",
      "2023-02-02 03:21:08,847 Vendo Un lote De 30 vestidos nuevos para ni帽as colores y Modelos Variados.\n",
      "2023-02-02 03:21:08,847 Item 375 scrapeado con 茅xito\n",
      "2023-02-02 03:21:10,889 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:10,890 Scrapeando item 376\n",
      "2023-02-02 03:21:16,074 Mangas malla\n",
      "2023-02-02 03:21:16,074 Item 376 scrapeado con 茅xito\n",
      "2023-02-02 03:21:18,111 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:18,112 Scrapeando item 377\n",
      "2023-02-02 03:21:23,310 Pijamas Para Dama\n",
      "2023-02-02 03:21:23,310 Item 377 scrapeado con 茅xito\n",
      "2023-02-02 03:21:25,338 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:25,340 Scrapeando item 378\n",
      "2023-02-02 03:21:30,554 SANDALIAS EVA\n",
      "2023-02-02 03:21:30,554 Item 378 scrapeado con 茅xito\n",
      "2023-02-02 03:21:32,592 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:32,594 Scrapeando item 379\n",
      "2023-02-02 03:21:37,842 Hermosas sandalias paltita\n",
      "2023-02-02 03:21:37,842 Item 379 scrapeado con 茅xito\n",
      "2023-02-02 03:21:39,870 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:39,871 Scrapeando item 380\n",
      "2023-02-02 03:21:45,106 Vestido BCBG Max Azria\n",
      "2023-02-02 03:21:45,107 Item 380 scrapeado con 茅xito\n",
      "2023-02-02 03:21:47,142 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:47,144 Scrapeando item 381\n",
      "2023-02-02 03:21:52,420 Media Taloneras kawaii\n",
      "2023-02-02 03:21:52,420 Item 381 scrapeado con 茅xito\n",
      "2023-02-02 03:21:54,455 -------------------------------------------------------------------\n",
      "2023-02-02 03:21:54,457 Scrapeando item 382\n",
      "2023-02-02 03:21:59,747 Liquidaci贸n Sandalia Colloky Ni帽a\n",
      "2023-02-02 03:21:59,749 Item 382 scrapeado con 茅xito\n",
      "2023-02-02 03:22:01,775 -------------------------------------------------------------------\n",
      "2023-02-02 03:22:01,776 Scrapeando item 383\n",
      "2023-02-02 03:22:07,003 zapato modelo oxford 100% cuero guante con forro badana y planta caucho\n",
      "2023-02-02 03:22:07,004 Item 383 scrapeado con 茅xito\n",
      "2023-02-02 03:22:09,038 -------------------------------------------------------------------\n",
      "2023-02-02 03:22:09,040 Scrapeando item 384\n",
      "2023-02-02 03:22:14,243 Se venden\n",
      "2023-02-02 03:22:14,244 Item 384 scrapeado con 茅xito\n",
      "2023-02-02 03:22:16,274 -------------------------------------------------------------------\n",
      "2023-02-02 03:22:16,276 Scrapeando item 385\n",
      "2023-02-02 03:22:21,489 PANTALN JEANS SUPER STRECH 5 BOTONES 硷 LEVANTA COLA \n",
      "2023-02-02 03:22:21,489 Item 385 scrapeado con 茅xito\n",
      "2023-02-02 03:22:23,518 -------------------------------------------------------------------\n",
      "2023-02-02 03:22:23,567 Se hall贸 1 errores\n",
      "2023-02-02 03:22:23,569 Fin de la extraccion\n",
      "2023-02-02 03:22:23,570 Guardando Data\n",
      "2023-02-02 03:22:23,911 Data Guardados Correctamente\n",
      "2023-02-02 03:22:23,913 Guardando Error\n",
      "2023-02-02 03:22:23,935 Error Guardados Correctamente\n",
      "2023-02-02 03:22:23,936 Guardando tiempos\n",
      "2023-02-02 03:22:23,937 Productos Extra铆dos: 311\n",
      "2023-02-02 03:22:23,938 Hora Fin: 03:22:23\n",
      "2023-02-02 03:22:24,061 Tiempos Guardados Correctamente\n",
      "2023-02-02 03:22:24,063 Programa finalizado\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
