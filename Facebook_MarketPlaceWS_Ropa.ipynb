{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9825e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from json import loads, JSONDecodeError\n",
    "from logging import basicConfig, ERROR, INFO, log\n",
    "from os import _exit, getenv, makedirs, path\n",
    "from re import findall\n",
    "from time import localtime, sleep, strftime, time\n",
    "from traceback import TracebackException\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openpyxl import load_workbook\n",
    "from pandas import DataFrame\n",
    "from seleniumwire import webdriver\n",
    "from seleniumwire.utils import decode\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9318c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Errores:\n",
    "    def __init__(self):\n",
    "        self._errores = {\n",
    "            \"Clase\": [],\n",
    "            \"Mensaje\": [],\n",
    "            \"Linea de Error\": [],\n",
    "            \"Codigo Error\": [],\n",
    "            \"Publicacion\": []\n",
    "        }\n",
    "        \n",
    "    def _get_errores(self):\n",
    "        return self._errores\n",
    "    \n",
    "    def _append_error(self, error, enlace):\n",
    "        traceback_error = TracebackException.from_exception(error)\n",
    "        error_message = traceback_error._str\n",
    "        error_stack = traceback_error.stack[0]\n",
    "        log(ERROR, error_message)  \n",
    "        self._errores[\"Clase\"].append(traceback_error.exc_type)\n",
    "        self._errores[\"Mensaje\"].append(error_message)\n",
    "        self._errores[\"Linea de Error\"].append(error_stack.lineno)\n",
    "        self._errores[\"Codigo Error\"].append(error_stack.line)\n",
    "        self._errores[\"Publicacion\"].append(enlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abc9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self._dataset = {\n",
    "            \"Fecha Extraccion\": [],\n",
    "            \"titulo_marketplace\": [],\n",
    "            \"tiempo_creacion\": [],\n",
    "            \"tipo_delivery\": [],\n",
    "            \"delivery_data\": [],\n",
    "            \"delivery_direccion\": [],\n",
    "            \"descripcion\": [],\n",
    "            \"disponible\": [],\n",
    "            \"vendido\": [],\n",
    "            \"fecha_union_vendedor\": [],\n",
    "            \"cantidad\": [],\n",
    "            \"precio\": [],\n",
    "            \"tipo_moneda\": [],\n",
    "            \"amount_with_concurrency\": [],\n",
    "            \"latitud\": [],\n",
    "            \"longitud\": [],\n",
    "            \"locacion\": [],\n",
    "            \"locacion_id\": [],\n",
    "            \"name_vendedor\": [],\n",
    "            \"tipo_vendedor\": [],\n",
    "            \"id_vendedor\": [],\n",
    "            \"enlace\": []\n",
    "        }\n",
    "        \n",
    "    def _get_dataset(self):\n",
    "        return self._dataset\n",
    "    \n",
    "    def _append_data(self, item, fecha_extraccion, enlace):\n",
    "        self._dataset[\"titulo_marketplace\"].append(item.get('marketplace_listing_title'))\n",
    "        self._dataset[\"tiempo_creacion\"].append(item.get('creation_time'))\n",
    "        self._dataset[\"disponible\"].append(item.get('is_live'))\n",
    "        self._dataset[\"vendido\"].append(item.get('is_sold'))\n",
    "        self._dataset[\"cantidad\"].append(item.get('listing_inventory_type'))\n",
    "        self._dataset[\"name_vendedor\"].append(item.get('story').get('actors')[0].get('name'))\n",
    "        self._dataset[\"tipo_vendedor\"].append(item.get('story').get('actors')[0]['__typename'])\n",
    "        self._dataset[\"id_vendedor\"].append(item.get('story').get('actors')[0]['id'])\n",
    "        self._dataset[\"locacion_id\"].append(item.get('location_vanity_or_id'))\n",
    "        self._dataset[\"latitud\"].append(item.get('location', {}).get('latitude'))\n",
    "        self._dataset[\"longitud\"].append(item.get('location', {}).get('longitude'))\n",
    "        self._dataset[\"precio\"].append(item.get('listing_price', {}).get('amount'))\n",
    "        self._dataset[\"tipo_moneda\"].append(item.get('listing_price', {}).get('currency'))\n",
    "        self._dataset[\"amount_with_concurrency\"].append(item.get('listing_price', {}).get('amount_with_offset_in_currency'))\n",
    "        self._dataset[\"tipo_delivery\"].append(item.get('delivery_types', [None])[0])\n",
    "        self._dataset[\"delivery_data\"].append(item.get(\"delivery_data\", {}).get('carrier'))\n",
    "        self._dataset[\"delivery_direccion\"].append(item.get(\"delivery_data\", {}).get('delivery_address'))\n",
    "        self._dataset[\"descripcion\"].append(item.get('redacted_description', {}).get('text'))\n",
    "        self._dataset[\"fecha_union_vendedor\"].append(item.get('marketplace_listing_seller', {}).get('join_time'))  \n",
    "        data = item.get('location_text', {})\n",
    "        if data:\n",
    "            data = data.get('text')\n",
    "        self._dataset[\"locacion\"].append(data)\n",
    "        self._dataset[\"Fecha Extraccion\"].append(fecha_extraccion)\n",
    "        self._dataset[\"enlace\"] = enlace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5abe3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tiempo:\n",
    "    def __init__(self, start):\n",
    "        self._hora_inicio = strftime(\"%H:%M:%S\", localtime(start))\n",
    "        log(INFO, f\"Hora de inicio: {self._hora_inicio}\")\n",
    "        self._fecha = (datetime.now().date() - timedelta(days=1)).strftime('%d/%m/%Y')\n",
    "        self._hora_fin = None\n",
    "        self._cantidad = None\n",
    "        self._tiempo = None\n",
    "        self._productos_por_min = None\n",
    "        self._enlace = None\n",
    "        self._observaciones = None\n",
    "        self._errores = None\n",
    "        \n",
    "    def _get_fecha(self):\n",
    "        return self._fecha\n",
    "    \n",
    "    def _get_errores(self):\n",
    "        return self._errores\n",
    "    \n",
    "    def _set_cantidad(self, cantidad):\n",
    "        self._cantidad = cantidad\n",
    "    \n",
    "    def _set_errores(self, errores):\n",
    "        self._errores = errores\n",
    "    \n",
    "    def _set_param_final(self, start):\n",
    "        end = time()\n",
    "        self._hora_fin = strftime(\"%H:%M:%S\", localtime(end))\n",
    "        log(INFO, f\"Productos Extraídos: {self._cantidad}\")\n",
    "        log(INFO, f\"Hora Fin: {self._hora_fin}\")\n",
    "        total = end - start\n",
    "        self._tiempo = str(timedelta(seconds=total)).split(\".\")[0]\n",
    "        self._productos_por_min = int(self._cantidad /(total / 60))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e788fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScraperFb:\n",
    "    \"\"\"Representa a un bot para hacer web scarping en fb marketplace.\n",
    "\n",
    "    Attributes:\n",
    "        driver (Object): Maneja un navegador para hacer web scraping\n",
    "        wait (Object): Maneja el Tiempo de espera durante la ejecución del bot\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, start):\n",
    "        \"\"\"Inicializa un objeto de tipo ScraperFb.\n",
    "\n",
    "        Args:\n",
    "            driver (Object): [Driver]\n",
    "            wait (Object): [Wait]\n",
    "        \"\"\"\n",
    "        log(INFO, \"Inicializando scraper\")\n",
    "        self._tiempo = Tiempo(start)\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "        chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "        self.driver = webdriver.Chrome(chrome_options=chrome_options,service=Service(ChromeDriverManager().install()))\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "        self._errores = Errores()\n",
    "        self._data = Dataset()\n",
    "\n",
    "    def _get_data(self):\n",
    "        return self._data\n",
    "    \n",
    "    def _get_errores(self):\n",
    "        return self._errores\n",
    "        \n",
    "    def iniciar_sesion(self, url):\n",
    "        \"\"\"Inicia sesión en una página web usando un usuario y contraseña\n",
    "\n",
    "        Args:\n",
    "            url (str): [Url]\n",
    "        \"\"\"\n",
    "        log(INFO, \"Iniciando sesión\")\n",
    "        self.driver.get(url)\n",
    "        self.driver.maximize_window()\n",
    "        username = self.wait.until(EC.presence_of_element_located((By.ID, \"email\")))\n",
    "        password = self.wait.until(EC.presence_of_element_located((By.ID, \"pass\")))\n",
    "        username.clear()\n",
    "        password.clear()\n",
    "        username.send_keys(getenv('FB_USERNAME'))\n",
    "        password.send_keys(getenv('FB_PASSWORD'))\n",
    "        self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[name='login']\"))).click()\n",
    "        log(INFO, \"Inicio de sesión con éxito\")\n",
    "        \n",
    "    def mapear_datos(self, url):\n",
    "        sleep(10)\n",
    "        log(INFO, \"Accediendo a la URL\")\n",
    "        self.driver.execute_script(\"window.open('about:blank', 'newtab');\")\n",
    "        self.driver.switch_to.window(\"newtab\")\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        sleep(8)\n",
    "        log(INFO, \"Mapeando Publicaciones\")\n",
    "        ropa = self.driver.find_elements(By.XPATH, '//*[@class=\"xt7dq6l xl1xv1r x6ikm8r x10wlt62 xh8yej3\"]')\n",
    "        fecha_publicacion = fecha_extraccion = int(datetime.strptime(self._tiempo._get_fecha(),\"%d/%m/%Y\").timestamp())\n",
    "        fecha_flag = fecha_extraccion + 86400\n",
    "        i=0\n",
    "        e=0\n",
    "        del self.driver.requests\n",
    "        \n",
    "        while fecha_publicacion >= fecha_extraccion:\n",
    "            log(INFO, f\"Scrapeando item {i + 1}\")\n",
    "            \n",
    "            try:\n",
    "                enlace = findall(\"(.*)\\/\\?\", ropa[i].find_element(By.XPATH, \".//ancestor::a\").get_attribute('href'))[0]\n",
    "            except NoSuchElementException as error:\n",
    "                enlace = None\n",
    "                self._errores._append_error(error, enlace)\n",
    "            \n",
    "            try:\n",
    "                ropa[i].click()\n",
    "                sleep(5)\n",
    "                for request in self.driver.requests:\n",
    "                    if not request.response or 'graphql' not in request.url:\n",
    "                        continue\n",
    "                    \n",
    "                    body = decode(request.response.body, request.response.headers.get('Content-Encoding', 'identity'))\n",
    "                    decoded_body = body.decode('utf-8')\n",
    "                    json_data = loads(decoded_body)\n",
    "                    \n",
    "                    if 'prefetch_uris_v2' not in json_data['extensions']:\n",
    "                        continue\n",
    "\n",
    "                    fecha_publicacion = json_data['data']['viewer']['marketplace_product_details_page']['target']['creation_time']\n",
    "                    #if fecha_publicacion < fecha_flag:\n",
    "                    dato = json_data['data']['viewer']['marketplace_product_details_page'][\"target\"]\n",
    "                    log(INFO, f\"{dato['marketplace_listing_title']}\")\n",
    "                    self._data._append_data(dato, self._tiempo._get_fecha(), enlace)\n",
    "                    log(INFO, f\"Item {i + 1} scrapeado con éxito\")\n",
    "                    break\n",
    "                self.driver.execute_script(\"window.history.go(-1)\");\n",
    "                \n",
    "            except (NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as error:\n",
    "                self._errores._append_error(error, enlace)\n",
    "                e=e+1\n",
    "                \n",
    "            except (KeyError, JSONDecodeError) as error:\n",
    "                self._errores._append_error(error, enlace)\n",
    "                e=e+1\n",
    "                self.driver.execute_script(\"window.history.go(-1)\")\n",
    "                \n",
    "            except Exception as error:\n",
    "                self._errores._append_error(error, enlace)\n",
    "                e = e + 1\n",
    "                print(error)\n",
    "                self.guardar_datos(self._errores._get_errores())\n",
    "                _exit(0)\n",
    "            i = i + 1\n",
    "            if i == len(ropa):\n",
    "                self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "                sleep(7)\n",
    "                ropa = self.driver.find_elements(By.XPATH, '//*[@class=\"xt7dq6l xl1xv1r x6ikm8r x10wlt62 xh8yej3\"]')\n",
    "            if i == 5:\n",
    "                break\n",
    "            \n",
    "            del self.driver.requests\n",
    "            log(INFO, \"-------------------------------------------------------------------\")\n",
    "            sleep(3)\n",
    "        self._tiempo._set_errores(e)\n",
    "        log(INFO, f\"Se halló {e} errores\")\n",
    "        log(INFO, \"Fin de la extraccion\")\n",
    "    \n",
    "    def guardar_datos(self, dataset, filetype = \"Data\", folder=\"Data\", filename=\"fb_data\"):\n",
    "        log(INFO, f\"Guardando {filetype}\")\n",
    "        df_fb_mkp_ropa = DataFrame(dataset)\n",
    "        if filetype == \"Data\":\n",
    "            df_fb_mkp_ropa.drop(len(df_fb_mkp_ropa)-1, axis=0, inplace=True)\n",
    "            cantidad = len(df_fb_mkp_ropa)\n",
    "            self._tiempo._set_cantidad(cantidad)\n",
    "        elif filetype == \"Error\":\n",
    "            cantidad = self._tiempo._get_errores()\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        datetime_obj = datetime.strptime(self._tiempo._get_fecha(),\"%d/%m/%Y\")\n",
    "        filepath = folder + \"/\" + datetime_obj.strftime('%d-%m-%Y') + \"/\"\n",
    "        filename = filename + \"_\" + datetime_obj.strftime('%d%m%Y') + \"_\" + str(cantidad) + \".xlsx\"\n",
    "        if not path.exists(filepath):\n",
    "            makedirs(filepath)\n",
    "        df_fb_mkp_ropa.to_excel(filepath + filename, index = False)\n",
    "        log(INFO, f\"{filetype} Guardados Correctamente\")\n",
    "        \n",
    "    def guardar_tiempos(self, filename, sheet_name, start):\n",
    "        log(INFO, \"Guardando tiempos\")\n",
    "        self._tiempo._set_param_final(start)\n",
    "        tiempos = load_workbook(filename)\n",
    "        header_exist = True\n",
    "        if sheet_name not in [ws.title for ws in tiempos.worksheets]:\n",
    "            tiempos.create_sheet(sheet_name)\n",
    "            header_exist = False\n",
    "        worksheet = tiempos[sheet_name]\n",
    "        if not header_exist:\n",
    "            worksheet.append(list(self._tiempo.__dict__.keys()))\n",
    "        worksheet.append(list(self._tiempo.__dict__.values()))\n",
    "        tiempos.save(filename)\n",
    "        tiempos.close()\n",
    "        log(INFO, \"Tiempos Guardados Correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6838bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Formato para el debugger\n",
    "    basicConfig(format='%(asctime)s %(message)s')\n",
    "    log(INFO, \"Configurando Formato Básico del Debugger\")\n",
    "    \n",
    "    # Cargar variables de entorno\n",
    "    log(INFO, \"Cargando Variables de entorno\")\n",
    "    load_dotenv()\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    # Url base a scrapear\n",
    "    url_base = 'https://www.facebook.com/'\n",
    "    url_ropa = \"https://www.facebook.com/marketplace/category/apparel/?sortBy=creation_time_descend&exact=false\"\n",
    "    \n",
    "    # Parámetros para guardar la data extraída por el scraper\n",
    "    data_filename = \"fb_ropa\"\n",
    "    data_folder = data_type = \"Data\"\n",
    "    \n",
    "    # Parámetros para guardar la medición de la ejecución del scraper\n",
    "    filename_tiempos = 'Tiempos.xlsx'\n",
    "    sheet_tiempos = \"Ropa\"\n",
    "    \n",
    "    # Parámetros para guardar los errores durante la ejecución por el scraper\n",
    "    error_filename = \"fb_error\"\n",
    "    error_folder = error_type = \"Error\"\n",
    "    \n",
    "    scraper = ScraperFb(start)\n",
    "    scraper.iniciar_sesion(url_base)\n",
    "    scraper.mapear_datos(url_ropa)\n",
    "    \n",
    "    # Guardando la data extraída por el scraper\n",
    "    scraper.guardar_datos(scraper._get_data()._get_dataset(), data_type, data_folder, data_filename)\n",
    "    \n",
    "    # Guardando los errores extraídos por el scraper\n",
    "    scraper.guardar_datos(scraper._get_errores()._get_errores(), error_type, error_folder, error_filename)\n",
    "    \n",
    "    # Guardando los tiempos durante la ejecución del scraper\n",
    "    scraper.guardar_tiempos(filename_tiempos, sheet_tiempos, start)\n",
    "    \n",
    "    log(INFO, \"Programa ejecutado satisfactoriamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a430409",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89876e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
